{"count": 3439, "next": "http://pyvideo.org/api/v2/video/?page=75&format=json", "previous": "http://pyvideo.org/api/v2/video/?page=73&format=json", "results": [{"category": "SciPy 2014", "language": "English", "slug": "putting-the-v-in-ipython-vim-ipython-and-ipython", "speakers": ["Paul Ivanov"], "tags": [], "related_urls": [], "id": 2797, "state": 1, "title": "Putting the v in IPython: vim-ipython and ipython-vimception", "summary": "This talk will explain how to intimately integrate IPython with your favorite text editor, as well as how to customize the IPython Notebook interface to behave in a way that makes sense to *you*. Though the concrete examples are centered around the world-view of a particular text editor, the content will be valuable to anyone wishing to extend and customize IPython for their own purposes.\r\n", "description": "This talk will cover two projects: [vim-ipython](https://github.com/ivanov/vim-ipython) (1) and [ipython-vimception](https://github.com/ivanov/ipython-vimception) (2)\r\n\r\n**1.** Most people think of IPython as an application - but much of it is written as a\r\nlibrary, making it possible to integrate with other tools.\r\n\r\nvim-ipython is a Vim plugin that was first written during the sprints at SciPy\r\n2011 as a two-way interface between the Vim text editor and a running IPython\r\nkernel. It turns vim into a frontend for IPython kernels, like the qtconsole\r\nand the notebook interface. It allows you to send lines or whole files for\r\nIPython to execute, and also get back object introspection and word completions\r\nin Vim, like what you get with: object?`<enter>` and object.`<tab>` in IPython.  It\r\ncurrently has over 430 star gazers on GitHub.  Because vim-ipython simply\r\nleverages much of existing IPython machinery, it allows users to interact with\r\nnon-Python kernels (such as IJulia and IHaskell) in the same manner from the\r\nconvenience of their favorite text editor. More recently, vim-ipython has\r\ngained the ability to conveniently view and edit IPython notebooks (.ipynb\r\nfiles) without a running an IPython Notebook server. \r\n\r\nvim-ipython has a small and accessible code base (13 people have contributed\r\npatches to the project), which has frequently made it *the* reference example\r\nfor how to implement and utilize the IPython messaging protocol that allows for\r\nthe language-independent communication between frontends and kernels.\r\n\r\n**2.** The IPython Notebook user interface has become highly customizable, and\r\nauthoring code and content in the Notebook can be more pleasant and productive\r\nexperience if you take the time to make it yours.\r\n\r\nIPython 2.0 brings a modal notion to the Notebook interface.  There are two\r\nmodes: edit and mode command mode. In command mode, many single-key keyboard\r\nshortcuts are available. For example, `m` changes the current cell type to\r\nMarkdown, `a` and `b` will insert a new cell above and below the current one,\r\nand so on. Edit mode removes these single key shortcuts so that new code and\r\ntext can be typed in, but still retains a few familiar shortcuts, such as\r\n`Ctrl-Enter`, `Alt-Enter`, and `Shift-Enter` for cell execution (with some nuanced\r\ndifferences). \r\n\r\nPart of the motivation behind the introduction of this modal interface was that\r\nperforming operations on notebook cells became a tedious and awkward, as most\r\noperations required `Ctrl-m` to be typed too many times. For example, inserting 3 cells involved\r\n`Ctrl-m a Ctrl-m a Ctrl-m a`, whereas now it's just `aaa` in Command mode. But\r\nthe other major reason for the modal refactor was to make it possible to add\r\nand remove shortcuts. For example, a user who finds it annoying that `a` stands\r\nfor \"insert above\" and `b` for \"insert below\" and thinks that `a` for \"insert\r\nafter\" and `b` for \"insert before\" makes more sense will now be able to make\r\nthat change for herself.\r\n\r\nSome of the keyboard shortcuts in command mode are already vi-like (`j` and `k`\r\nto move up and down between cells) but many are not, and a few are confusingly\r\nplaced. ipython-vimception aims to be a reference implementation for how to\r\nperform shortcut and user interface customization in the notebook. In\r\nparticular, along with vim-ipython's new ability to edit .ipynb files,\r\nipython-vimception addresses the concerns of many die-hard vim aficionados.\r\nMany of them have otherwise shied away form the notebook interface as it\r\noffends their sensibilities for how text editing and document manipulation\r\nshould be done. However, with the new customizable shortcut system in IPython,\r\nalong with a vim emulation mode in cell text input areas, they finally will\r\nhave a way to stay productive without having to change their ways.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/p9gnhmX1sPo?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/p9gnhmX1sPo?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/p9gnhmX1sPo/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=p9gnhmX1sPo", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:40.676", "updated": "2014-07-16T14:22:28.296"}, {"category": "SciPy 2014", "language": "English", "slug": "pysi-a-python-framework-for-spatial-interaction", "speakers": ["Taylor Oshan"], "tags": [], "related_urls": [], "id": 2789, "state": 1, "title": "pySI  A Python Framework for Spatial Interaction Modelling", "summary": "Spatial Interaction Modelling is a method for calibrating parameters for components within a system of flows, such as migration or trade, and then using those parameters to estimate new flows. Despite their popularity, a unified Python framework to employ them does not exist. In response, pySI was created as a coherent tool for calibrating models and simulating flows for a variety of models.", "description": "Functions from libraries such as scipy.optimize, scipy.spatial, statsmodels,\r\nand numdifftools comprise the core of the pySI.calibrate routines, which are\r\nautomatically constructed depending upon the specified model inputs. As a\r\nresult, the user can focus on identifying different flow systems  and\r\nunderstanding the associated spatial processes, rather than the algorithmic\r\ndivergences which emerge between different models. After calibration is\r\ncompleted, the estimated parameters and their diagnostic statistics can be\r\nreported in a uniform fashion.  Using functions within pySI.simulate, the\r\nparameter estimates can act as inputs in order to predict new flows. More\r\nrecently developed models, which do not require input parameters, are also made\r\navailable, allowing comparisons amongst results from differing conceptual\r\nformulations. Finally, results may be visualized with plots and networks via\r\nmatplotlib, igraph, and networkx. Overall, the pySI framework will increase the\r\naccessibility of spatial interaction modelling while also serving as a tool\r\nwhich can help new users understand the associated methodological intricacies. \r\n\r\nWithin this presentation, the concept of spatial interaction and a few key\r\nmodelling terms will first be introduced, along with several example\r\napplications. Next, two traditional techniques for calibrating spatial\r\ninteraction models, Poisson generalized linear regression and direct maximum\r\nlikelihood estimation will be contrasted. It will then be demonstrated how this\r\nnew framework will allow users to execute either form of calibration using\r\nidentical input variables, which are based upon a pandas DataFrame\r\nspecification, without any significant mathematical or statistical training.\r\nResults from two different conceptual models will be compared to illustrate how\r\npySI can be used to explore different methods and models of spatial\r\ninteraction.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/VokeBZarsNM?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/VokeBZarsNM?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/VokeBZarsNM/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=VokeBZarsNM", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:39.813", "updated": "2014-07-16T14:23:24.208"}, {"category": "SciPy 2014", "language": "English", "slug": "python-beyond-cpython-adventures-in-software-dis", "speakers": ["Nick Coghlan"], "tags": [], "related_urls": [], "id": 2785, "state": 1, "title": "Python Beyond CPython: Adventures in Software Distribution", "summary": "", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/IVzjVqr_Bzs?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/IVzjVqr_Bzs?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/IVzjVqr_Bzs/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=IVzjVqr_Bzs", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:39.231", "updated": "2014-07-15T23:14:10.049"}, {"category": "SciPy 2014", "language": "English", "slug": "python-for-economists-and-other-social-scientist", "speakers": ["David Pugh"], "tags": [], "related_urls": [], "id": 2786, "state": 1, "title": "Python for economists (and other social scientists!)", "summary": "I have developed a curriculum for a three part, graduate level course on computational methods designed to increase the exposure of graduate students and researchers to basic techniques used in computational modeling and simulation using the Python programming language.", "description": "Together with theory and experimentation, computational modeling and simulation has become a \"third pillar\" of scientific enquiry.  I am developing a curriculum for a three part, graduate level course on computational methods designed to increase the exposure of graduate students and researchers in the College of Humanities and Social Sciences at the University of Edinburgh to basic techniques used in computational modeling and simulation using the Python programming language. My course requires no prior knowledge or experience with computer programming or software development and all current and future course materials will be made freely available online via GitHub.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/xHkGW1l5X8k?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/xHkGW1l5X8k?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/xHkGW1l5X8k/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=xHkGW1l5X8k", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:39.482", "updated": "2014-07-16T14:24:24.733"}, {"category": "SciPy 2014", "language": "English", "slug": "reflexive-data-science-on-scipy-communities", "speakers": ["Sebastian Benthall"], "tags": [], "related_urls": [], "id": 2809, "state": 1, "title": "Reflexive Data Science on SciPy Communities", "summary": "I present tools for collecting data generated by Scientific Python community development infrastructure (mailing list archives, pull requests, issue trackers) and analyzing it with Pandas and NetworkX. Showing preliminery results using social network analysis and complex systems modeling, I demonstrate using reflexive data science to enrich our understanding of open source development.", "description": "### Background/Motivation\r\n\r\nThe Scientific Python community's contributions to greater scientific understanding have been underappreciated by academic institutions. One reason for this is that software engineering is widely misunderstood and not recognized as research work in its own right, as opposed to paper publication and patents. A better understanding of the open source software development process itself will help academic institutions recognize the contributions of open source developers.\r\n\r\n\r\n### Methods\r\n\r\nI collect historical data from development of Scientific Python projects and render these into formats suitable for analysis using SciPy tools. To demonstrate the potential of this work, I will show two ways of analyzing this data scientifically: as a self-excited Hawkes process exibiting shock behavior, and as information diffusion over a social network.\r\n\r\n### Results\r\n\r\nThe purpose of this talk is twofold.\r\n\r\nFirst, to introduce tools and techniques for turning data from open source software production into scientific data suitable for analysis.  This talk proposes that there's an opportunity for SciPy to engage in _reflexive data science_, using its own data to learn more about how it functions and how to operate more efficiently.\r\n\r\nSecond, this talk will present visualizations of the data based on complex systems research and social network analysis. Building on prior work, these results will focus on the role of productive bursts in communications. Drawing on social network analysis and prior work on roles in Usenet communities and open source communities, this talk will provide historical insight into the interaction between SciPy communities.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/IL9KqJtTGw0?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/IL9KqJtTGw0?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/IL9KqJtTGw0/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=IL9KqJtTGw0", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:41.881", "updated": "2014-07-16T14:25:10.436"}, {"category": "SciPy 2014", "language": "English", "slug": "scientific-knowledge-management-with-web-of-trail", "speakers": ["Jon Riehl"], "tags": [], "related_urls": [], "id": 2808, "state": 1, "title": "Scientific Knowledge Management with Web of Trails", "summary": "Do you hate repeating yourself?  Want to know when your publication is repeating someone else?  The Web of Trails project is a solution to knowledge management that empowers users to quickly find repetition of key phrases.  Using syntactic indexing, as opposed to lexical techniques, this approach is capable of representing the literature using less space while providing high value results.", "description": "Web of Trails (WOT) is an open source project that uses context-free grammars (CFG's) as the basic building block for search. Current search technology relies upon the presence of words on a page, sometimes augmented with statistical correlations among words. Even with these restrictions, maintenance of an index requires storage much greater than the input size (a polynomial function of it). CFG's have been used for decades in compilation and language tools, and more recently in data compression.\r\n\r\nThe primary advantage of this CFG approach, based upon the Sequitur algorithm, is that it indexes content in linear-space, not polynomial-space. The secondary advantage is that combined with research in inference, grammars can express human concepts and connections rather than just correlations. This project uses grammar and syntactic analysis to replace lexical and word-based approaches to the problem of searching collections of digital artifacts. Benchmarking in web content indexing will be shown relative to popular alternatives such Apache Lucene and Amazon Cloud Search.\r\n\r\nIn addition to implementing content indexing with Sequitur, this project will enable domain-specific extensions of WOT. Once complete, we will research novel techniques for generalizing the grammars inferred by Sequitur. As this fundamental research develops, it will inform later framework development and increase search precision. This is a big leap in the state of the art, as text artifacts are no longer represented as bags of words, but as bags on non-terminals in a growing and adapting grammar.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/oEkKxHQb8iA?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/oEkKxHQb8iA?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/oEkKxHQb8iA/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=oEkKxHQb8iA", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:41.778", "updated": "2014-07-16T14:26:33.901"}, {"category": "SciPy 2014", "language": "English", "slug": "spatial-temporal-prediction-of-climate-change-imp", "speakers": ["Matthew Perry"], "tags": ["Tech"], "related_urls": [], "id": 2794, "state": 1, "title": "Spatial-Temporal Prediction of Climate Change Impacts using pyimpute, scikit learn and GDAL", "summary": "In this talk, I\\u2019ll show how we apply climate change models to predict shifts in agricultural zones across the western US. I will outline the use of the pyimpute, GDAL and scikit-klearn to perform supervised classification; training a model using current climatic conditions to predict spatially-explicit zones under future climate scenarios.", "description": "As the field of climate modeling continues to mature, we must anticipate the practical implications of the climatic shifts predicted by these models. In this talk, I'll show how we apply the results of climate change models to predict shifts in agricultural zones across the western US. I will outline the use of the Geospatial Data Abstraction Library ([GDAL](http://www.gdal.org/)) and Scikit-Learn ([sklearn](http://scikit-learn.org/)) to perform supervised classification, training the model using current climatic conditions and predicting the zones as spatially-explicit raster surfaces across a range of future climate scenarios. Finally, I'll present a python module ([pyimpute](https://github.com/perrygeo/pyimpute)) which provides an API to optimize and streamline the process of spatial classification and regression problems.\r\n\r\n#### Outline\r\nThis talk will consist of four parts:\r\n\r\n1. A brief overview of climate data and the concept of agro-ecological zones\r\n2. The theory and intuition behind bioclimatic envelope modeling using supervised classification\r\n3. Visualization and interpretation of our results\r\n4. Detailed demonstration of the pyimpute/GDAL/sklearn workflow \r\n\r\n    * Loading spatial data into numpy arrays \r\n    * Random stratified sampling\r\n    * Training, assessing and selecting the sklearn classifier\r\n    * Prediction of zones given future climate data as explanatory variables\r\n    * Quantifying and interpreting uncertainty\r\n    * Writing results to spatial data formats\r\n    * Discussion of performance and memory limitations\r\n    * Visualizing and interacting with the results\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/7mmbRNE9VsA?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/7mmbRNE9VsA?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/7mmbRNE9VsA/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=7mmbRNE9VsA", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:40.343", "updated": "2014-07-16T14:27:49.000"}, {"category": "SciPy 2014", "language": "English", "slug": "synthesis-and-analysis-of-circuits-in-the-ipython", "speakers": ["Nikolas Tezak"], "tags": [], "related_urls": [], "id": 2801, "state": 1, "title": "Synthesis and analysis of circuits in the IPython notebook", "summary": "Building on the new IPython 2.0 widget model and the jsPlumb package we create a schematic capture tool that allows graphically editing a circuit as well as its components' parameters and then instantly updating a domain specific modeling backend. This allows for an integrated circuit modeling workflow and to extend widget-based user interfaces for engineering and research projects.", "description": "Circuits, i.e., a network of interconnected components with ports, have found application in various scientific and engineering domains, ranging from applications close to the physical implementation, such as electrical circuits, photonic circuits for optical information processing, superconducting quantum circuits for quantum information applications to more abstract circuit representations of dynamical systems, biological processes or even software algorithms.\r\n\r\nThis has already led to the development of quite general domain-independent circuit modeling toolkits such as [Modelica](https://www.modelica.org/), but to date, there exist very few open source graphical general circuit editing environments that can be tightly integrated with custom, domain-specific implementation simulation or analysis backends as well as [IPython](http://ipython.org).\r\n\r\nHere we present our first attempt at creating such a tool as well as some applications from our own research on nano-photonic quantum circuit models. Our existing [QNET](http://mabuchilab.github.io/QNET/) software package allows to model these circuits in a purely symbolic fashion and interfaces with various codes for numerical simulation. \r\n\r\nWe demonstrate that the extension of our package with a visual circuit editor leads to a rich integrated simulation and analysis workflow in which an engineer or researcher can receive very fast feedback when making changes to his model.\r\n\r\nAs a consequence, it is much easier to build intuition for the particular kinds of circuit models and find novel and creative solutions to an engineering task.\r\n\r\nFinally, given the broad range of applications for circuit models and representations, we outline how our visual circuit editor can be adapted to export a circuit for interfacing with other domain specific software such as Modelica.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/-kUzWdKOgqc?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/-kUzWdKOgqc?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/-kUzWdKOgqc/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=-kUzWdKOgqc", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:41.080", "updated": "2014-07-16T14:29:00.050"}, {"category": "SciPy 2014", "language": "English", "slug": "the-placeiq-location-based-analytic-platform", "speakers": ["Eliza Chang"], "tags": [], "related_urls": [], "id": 2791, "state": 1, "title": "The PlaceIQ Location Based Analytic Platform", "summary": "PlaceIQ's patented platform analyzes half a trillion diverse data points about location, time, and real-world behavior to define human audiences and allow businesses to understand consumers at scale. It ingests large volumes of mobile activity data and geographic data, calling for creative use machine learning techniques to enable the high-fidelity abstractions insightful to businesses.", "description": "The surge in mobile device adoption and the subsequent abundance of time-stamped location data have given rise to possibilities and interest in understanding movement-based human behavior. The PlaceIQ analytic platform is a large-scale data analysis system that addresses this demand, providing a large-scale, flexible, and reliable platform created around the concepts of location and audience. The platform's data processing piece ingests large volumes of mobile activity data daily and overlays them onto geospatial data. These data include: the discretization of the U.S. into 1 billion 100 meter by 100 m tiles; more than 400,000 proprietary polygons delineating the shapes of properties and businesses; business listings and census data; and terabytes of mobile activity data. We discuss here the methodologies - namely DBSCAN clustering and kd-trees - used to de-dupe disparate geodata sources and evaluate the quality of noisy activity data at scale. The resulting overlays of people, places, and time create high-fidelity abstractions and manipulations insightful to businesses, particularly in the mobile advertising domain.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/ygI1LP_jD9A?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/ygI1LP_jD9A?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/ygI1LP_jD9A/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=ygI1LP_jD9A", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:40.036", "updated": "2014-07-16T14:30:53.555"}, {"category": "SciPy 2014", "language": "English", "slug": "tracpy-wrapping-the-fortran-lagrangian-trajector", "speakers": ["Kristen Thyng"], "tags": [], "related_urls": [], "id": 2805, "state": 1, "title": "TracPy: Wrapping the FORTRAN Lagrangian trajectory model TRACMASS", "summary": "An example of a Python wrapper of a FORTRAN code, applications of a Lagrangian trajectory model, and lessons learned about code development.", "description": "Numerical Lagrangian tracking is a way to follow parcels of fluid as they are advected by a numerical circulation model. This is a natural method to investigate transport in a system and understand the physics on the wide range of length scales that are actually experienced by a drifter. TRACMASS is a tool for Lagrangian trajectory modeling that has been developed over the past two decades. It has been used to better understand physics and its applications to real-world problems in many areas around the world, in both atmospheric and oceanic settings. TRACMASS is written in FORTRAN, which is great for speed but not as great for ease of use. This code has been wrapped in Python to run batches of simulations and improve accessibility --- and dubbed TracPy. \r\n\r\nIn this talk, I will outline some of the interesting features of the TRACMASS algorithm and several applications, then discuss the layout of the TracPy code. The code setup and organization have been a learning process and I will also share some of my hard-earned lessons.\r\n\r\nTracPy is continually in development and is available [on GitHub](https://github.com/kthyng/tracpy).\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/8poLWacun50?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/8poLWacun50?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/8poLWacun50/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=8poLWacun50", "whiteboard": "", "recorded": "2014-07-13", "added": "2014-07-15T22:45:41.472", "updated": "2014-07-16T14:31:36.766"}, {"category": "SciPy 2014", "language": "English", "slug": "advanced-3d-seismic-visualizations-in-python", "speakers": ["Joe Kington"], "tags": [], "related_urls": [], "id": 2821, "state": 1, "title": "Advanced 3D Seismic Visualizations in Python", "summary": "3D reflection seismic data collected as a part of the NanTroSEIZE project revealed complex interactions between active sedimentation and tectonics in the Nankai Trough, Japan. We implemented co-rendering of multiple attributes and stratal slicing in python to better visualize the structural and stratigraphic relationships within the piggyback slope basins of the accretionary prism.", "description": "3D reflection seismic data acquired [offshore of southeast Japan](http://www.geology.wisc.edu/~jkington/scipy2014/LocationMap.png \"Location Map\") as part of the Nankai Trough Seismogenic Zone Experiment  (NanTroSEIZE) provides a unique opportunity to study active accretionary prism processes.  The 3D seismic volume revealed complex interactions between active sedimentation and tectonics within [multiple slope basins](http://www.geology.wisc.edu/~jkington/scipy2014/inline_2695_w_interp_brown_seismic.png \"Cross section through entire accretionary prism illustrating multiple isolated sedimentary basins\") above the accretionary prism. However, our ability to understand these interactions was hindered without access to expensive specialized software packages. \r\n\r\nWe implemented stratal slicing of the 3D volume and co-rendering of multiple attributes in python to better visualize our results.  Stratal slicing allows volumetric attributes to be displayed [in map view along an arbitrary geologic timeline](http://www.geology.wisc.edu/~jkington/scipy2014/stratal_slicing_animation.gif \"Stratal Slicing Animation\")(~30MB animated gif) by interpolating between interpreted geologic surfaces.  This enhances the visibility of subtle changes in stratigraphic architecture through time. Co-rendering coherence on top of seismic amplitudes facilitates fault interpretation in both cross section and map view.  This technique allowed us to [confidently interpret faults](http://www.geology.wisc.edu/~jkington/scipy2014/ContemporaneousStrikeSlipAndNormalFaults.png \"Corendering attributes for fault interpretation\") near the limit of seismic resolution.  \r\n\r\nThe scientific python ecosystem proved to be an effective platform both for making publication-quality cross sections and for rapidly implementing state-of-the-art seismic visualization techniques. We created [publication quality cross sections](http://www.geology.wisc.edu/~jkington/scipy2014/Basin_uplift.png \"Example cross section\") (some annotations added in Inkscape) and interactive 2D visualizations in ``matplotlib``.  For 3D display of seismic volumes we used ``mayavi`` to easily create interactive scenes. ``scipy.ndimage`` provided most of the underlying image processing capability and allowed us to preform memory-efficient operations on >10GB arrays.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/PFOd01fqcyQ?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/PFOd01fqcyQ?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/PFOd01fqcyQ/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=PFOd01fqcyQ", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:43.185", "updated": "2014-07-16T14:32:33.304"}, {"category": "SciPy 2014", "language": "English", "slug": "behind-the-scenes-of-the-university-and-supplier", "speakers": ["Alexis Perez"], "tags": [], "related_urls": [], "id": 2813, "state": 1, "title": "Behind the Scenes of the University and Supplier Relationship", "summary": "The University of California, Berkeley and San Francisco combined are one of the largest buyers in the Bay Area. Historically, it has been a time-consuming process to analyze suppliers' proposed price files and ensure the University is not paying more than contracted. Through the use of Pandas and Python, this once tedious and manual process can routinely be done in a matter of a few seconds.\r\n", "description": "For the University of California, Berkeley and San Francisco, a routine management process of supplier price files used to be a time-consuming process. It is essential to analyze the sometimes tens of thousands of items a supplier offers to make sure the University doesn't accept larger price increases than is in compliance with a contract. A historical figure of past purchases is matched against the current and proposed catalogs and then analyzed to ultimately find out the percentage increase and number of products removed. Each Universities' motivation is to not accept a file that has larger price increases than contracted nor a file with several previously purchased products removed. \r\n\r\nTo combat the tedious and time-consuming process of manually analyzing the previous spend with the current and proposed files, a Python script was written. This heavily uses Pandas as well as Numpy for computations. The code uploads all three files as a dataframes and creates a common variable to compare similar products. It matches what was previously purchased to the identical products in the current and proposed catalogs. After filtering any 'bad' input that would skew the results, several values are computed and the code outputs the necessary figures to determine if a supplier's price file is acceptable. The code even documents each catalog result automatically so the historical changes are organized and noted in a csv.  \r\n\r\nThis code is an exponential improvement to the manual process that was historically done. The end numbers are known in a matter of seconds as opposed to hours of Excel or Access analysis. For some suppliers, Excel is even incapable of uploading the entire catalog, thus making any analysis nearly impossible. Python and Pandas have not only made the analysts time more efficient but have opened the door for several possibilities.\r\n\r\nAlthough this code has greatly improved this continuous analysis, more advanced techniques could potentially improve the process. The department soon hopes to use a forecasted spend figure rather than a historical snapshot to project spend against the proposed catalog. Moving forward, having the analysts armed with Python knowledge, Strategic Sourcing hopes to yield more meaning through the daily flow of spend data through machine learning techniques.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/dIpLLwIVCYY?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/dIpLLwIVCYY?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/dIpLLwIVCYY/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=dIpLLwIVCYY", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:42.296", "updated": "2014-07-16T14:34:05.663"}, {"category": "SciPy 2014", "language": "English", "slug": "blaze-building-a-foundation-for-array-oriented-c", "speakers": ["Mark Wiebe", "Matthew Rocklin"], "tags": [], "related_urls": [{"url": "https://github.com/mrocklin/blaze-scipy-2014", "description": "Slides and materials"}], "id": 2811, "state": 1, "title": "Blaze: Building a Foundation for Array-Oriented Computing in Python", "summary": "The Blaze project is a collection of libraries being built towards the goal of generalizing NumPy's data model and working on distributed data. This talk covers each of these libraries, and how they work together to accomplish this goal.", "description": "Python's scientific computing and data analysis ecosystem, built around NumPy, SciPy, Matplotlib, Pandas, and a host of other libraries, is a tremendous success. NumPy provides an array object, the array-oriented ufunc primitive, and standard practices for exposing and writing numerical libraries to Python all of which have assisted in making it a solid foundation for the community. Over time, however, it has become clear that there are some limitations of NumPy that are difficult to address via evolution from within. Notably, the way NumPy arrays are restricted to data with regularly strided memory structure on a single machine is not easy to change.\r\n\r\nBlaze is a project being built with the goal of addressing these limitations, and becoming a foundation to grow Python's success in array-oriented computing long into the future. It consists of a small collection of libraries being built to generalize NumPy's notions of array, dtype, and ufuncs to be more extensible, and to represent data and computation that is distributed or does not fit in main memory.\r\n\r\nDatashape is the array type system that describes the structure of data, including a specification of a grammar and set of basic types, and a library for working with them. LibDyND is an in-memory array programming library, written in C++ and exposed to Python to provide the local representation of memory supporting the datashape array types. BLZ is a chunked column-oriented persistence storage format for storing Blaze data, well-suited for out of core computations. Finally, the Blaze library ties these components together with a deferred execution graph and execution engine, which can analyze desired computations together with the location and size of input data, and carry out an execution plan in memory, out of core, or in a distributed fashion as is needed.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/9HPR-1PdZUk?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/9HPR-1PdZUk?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/9HPR-1PdZUk/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=9HPR-1PdZUk", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:42.088", "updated": "2014-07-23T12:42:03.566"}, {"category": "SciPy 2014", "language": "English", "slug": "building-petabyte-scale-comparative-genomics-pipe", "speakers": ["Chris Cope"], "tags": [], "related_urls": [], "id": 2818, "state": 1, "title": "Building petabyte-scale comparative genomics pipelines", "summary": "This talk will educate the audience about Python tools and best practices for creating reproducible petabyte-scale pipelines. This is done within the context of demonstrating a new grammar-based approach to comparative genomics. The genome grammars are produced using public data from the National Institutes of Health, streamed over a high-throughput Internet2 connection to Amazon Web Services.", "description": "We introduce a high-performance, open-source application written in Python that models genomic data with a context-free grammar (CFG), a construct from formal language theory. This approach is intended to advance fundamental science by delivering a more extensive model of the genetic interaction of diseases. Current comparative models treat genomic sequences as strings, and recent advances are little more than optimizations of the \\\"grep approach\\\". However a genome is a grammar: it is parsed, follows rules, and has an inherent hierarchical structure. Understanding the structure and rules of this implied grammar are essential for mapping loci to diseases when those loci are distributed across genomic regions.\r\n\r\nTo produce the CFGs, we have implemented the Sequitur algorithm to run on the AWS Elastic MapReduce platform. This application is written in Python and uses the following packages: MRjob, boto, and pandas. This is a petascale computing pipeline that is successful because it uses inherently scalable services and is able to take advantage of the 100G Internet2 connection between Amazon Web Services and the National Institutes of Health (NIH). This architecture delivers unprecedented transfer speeds and relatively low latency.\r\n\r\nWe discuss the advantages of this architecture, especially for groups without comparable local resources. In reviewing the results of our computation, we not only look at methods to measure the utility of our CFG models, but also the computational advantages of this approach. Just like the fastest alignment algorithms, this complex approach still operates  within linear-space. In addition, future pairwise comparisons are faster because our CFGs act as a compressed representation of the raw sequence data. Our hope is that this CFG approach is further tested as a replacement for raw sequence analysis. In addition, we hope that our  bioinformatics pipeline serves as an example for the SciPy community on how to perform large computations across the many petabytes made available by NIH.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/g_QVAp1YkRI?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/g_QVAp1YkRI?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/g_QVAp1YkRI/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=g_QVAp1YkRI", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:42.816", "updated": "2014-07-16T14:35:46.155"}, {"category": "SciPy 2014", "language": "English", "slug": "clustering-of-high-content-images-to-discover-off", "speakers": ["Juan Nunez-Iglesias"], "tags": [], "related_urls": [], "id": 2817, "state": 1, "title": "Clustering of high content images to discover off target phenotypes", "summary": "In high content imaging screens, cells are subjected to various treatments (usually shutting down specific genes) in high throughput, imaged, and a phenotype of interest measured. We argue that there is a wealth of information to be found in off-target phenotypes, and present an image clustering approach to discover these and infer gene function.", "description": "In the decade between 1999 and 2008, more newly-approved, first-in-class drugs were found by phenotypic screens than by molecular target-based approaches. This is despite far more resources being invested in the latter, and highlights the rising importance of screens in biomedical research. ([Swinney and Anthony, Nat Rev Drug Discov, 2011](http://www.nature.com/nrd/journal/v10/n7/full/nrd3480.html))\r\n\r\nDespite this success, the data from phenotypic screens is vastly underutilized. A typical analysis takes millions of images, obtained at a cost of, say, $250,000, and reduces each to a single number, a quantification of the phenotype of interest. The images are then ranked by that value and the top-ranked images are flagged for further investigation. ([Zanella et al, Trends Biotech, 2010](https://www.cell.com/trends/biotechnology/abstract/S0167-7799(10)00035-1))\r\n\r\nThe images, however, contain a lot more information than just a single phenotypic number. For one, usually only the mean phenotype of all the cells in the image is reported, with no information about variability, even though the distribution of cell shapes in a single image is highly informative ([Yin et al, Nat Cell Biol, 2013](http://www.nature.com/ncb/journal/v15/n7/full/ncb2764.html)). Additionally, cells display a variety of off-target phenotypes, independently of the target, that can provide biological insight and new research avenues.\r\n\r\nWe are developing an unsupervised clustering pipeline, tentatively named high-content-screen unsupervised sample clustering ([HUSC](http://github.com/jni/husc)), that leverages the scientific Python stack, particularly `scipy.stats`, `pandas`, `scikit-image`, and `scikit-learn`, to summarize images with feature vectors, cluster them, and infer the functions of genes corresponding to each cluster. The library includes functions for preprocessing images, computing an array of features designed specifically for microscopy images, and accessing a MongoDB database containing sample data. Its API allows easy extensibility by placing screen-specific functions under the `screens` sub-package. An example IPython notebook with a preliminary analysis can be found [here](http://jni.github.io/notebooks/hcs_nb.html).\r\n\r\nWe plan to use this library to develop a flexible web interface for flexible and extensible analysis of high-content screens, and relish the opportunity to enlist the help and expertise of the SciPy crowd.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/fn8F_NerTug?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/fn8F_NerTug?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/fn8F_NerTug/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=fn8F_NerTug", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:42.712", "updated": "2014-07-16T14:47:01.481"}, {"category": "SciPy 2014", "language": "English", "slug": "lightning-talks-scipy-2014-july-9-2014", "speakers": [], "tags": [], "related_urls": [], "id": 2814, "state": 1, "title": "Lightning Talks | SciPy 2014 | July 9, 2014", "summary": "", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/SMyto7WHiNs?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/SMyto7WHiNs?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/SMyto7WHiNs/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=SMyto7WHiNs", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:42.403", "updated": "2014-07-15T23:13:33.748"}, {"category": "SciPy 2014", "language": "English", "slug": "scikit-bio-core-bioinformatics-data-structures-a", "speakers": ["J Gregory Caporaso"], "tags": [], "related_urls": [], "id": 2815, "state": 1, "title": "scikit-bio: core bioinformatics data structures and algorithms in Python", "summary": "We present scikit-bio, a library based on the Python scientific computing stack implementing core bioinformatics data structures, algorithms and parsers. scikit-bio is useful for students in bioinformatics, who can learn topics such as iterative progressive multiple sequence alignment from the source code and accompanying documentation, and for real-world bioinformatics applications developers.", "description": "Python is widely used in computational biology, with many high profile bioinformatics software projects, such as [Galaxy](http://galaxyproject.org/), [Khmer](http://khmer.readthedocs.org/en/latest/) and [QIIME](http://www.qiime.org), being largely or entirely written in Python. We present [scikit-bio](http://www.scikit-bio.org), a new library based on the standard Python scientific computing stack (e.g., numpy, scipy, and matplotlib) implementing core bioinformatics data structures, algorithms, parsers, and formatters. scikit-bio is the first bioinformatics-centric [scikit](https://scikits.appspot.com/), and arises from over ten years of development efforts on [PyCogent](http://www.pycogent.org) and [QIIME](http://www.qiime.org), representing an effort to update the functionality provided by these extensively used tools, and to make that functionality more accessible. scikit-bio is intended to be useful both as a resource for students, who can learn topics such as heuristic-based sequence database searching or iterative progressive multiple sequence alignment from the source code and accompanying documentation, and as a powerful library for 'real-world' bioinformatics developers. To achieve these goals, scikit-bio development is centered around test-driven, peer-reviewed software development; C/Cython integration for computationally expensive algorithms; extensive API documentation and doc-testing based on the [numpy docstring standards](https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt); user documentation and [theoretical discussion of topics in IPython Notebooks](http://caporasolab.us/An-Introduction-To-Applied-Bioinformatics/); adherence to PEP8; and continuous integration testing. scikit-bio is available free of charge under the BSD license.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/hgBx_DBiPxA?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/hgBx_DBiPxA?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/hgBx_DBiPxA/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=hgBx_DBiPxA", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:42.515", "updated": "2014-07-16T14:50:23.679"}, {"category": "SciPy 2014", "language": "English", "slug": "software-carpentry-lessons-learned-0", "speakers": ["Greg Wilson"], "tags": [], "related_urls": [{"url": "http://dx.doi.org/10.12688/f1000research.3-62.v1", "description": "Wilson G. Software Carpentry: lessons learned [v1; ref status: indexed, http://f1000r.es/2x7] F1000Research 2014, 3:62 (doi: 10.12688/f1000research.3-62.v1) - See more at: http://f1000research.com/articles/3-62/v1#sthash.wFA62aN0.dpuf"}, {"url": "http://third-bit.com/scipy2014/", "description": "talk slides"}], "id": 2812, "state": 1, "title": "Software Carpentry: Lessons Learned", "summary": "", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/1e26rp6qPbA?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/1e26rp6qPbA?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/1e26rp6qPbA/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=1e26rp6qPbA", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:42.194", "updated": "2014-10-08T11:13:50.793"}, {"category": "SciPy 2014", "language": "English", "slug": "teaching-python-to-undergraduate-students", "speakers": ["Dominik Klaes"], "tags": [], "related_urls": [], "id": 2819, "state": 1, "title": "Teaching Python to undergraduate students", "summary": "Teaching undergraduate students in programming is interesting and challenging at the same time, because one has to deal mostly with two types: Those who have already experience and those who have not. I will present two models from Bonn University for Physics students with now much more responsibility for the tutors and would like to initiate discussions about different systems all over the world.", "description": "Teaching undergraduate students in programming languages like Python is interesting and challenging at the same time. You have to deal mostly with two types of students: Those who have already some experience in programming (not neccessarily Python), e.g. from high school, and those who have not. At Bonn University we have recently changed the structure of such a course for Bachelor of Science in Physics students. First, we include the Python tutorial in a lecture in the first term instead of a voluntary course in the lecture-free time before the fourth semester, where the \"Numerical Methods for Physicists\" course takes place. Second, instead of a weekly lecture, in which the topics are explained in detail, and a 2 hours exercise class, the new system provides only one introduction lecture per topic but a 3 hours exercise class per week. So especially the tutors are much more responsible for the success of the students in the final report of this course. Furthermore, as a student representative and also tutor for both courses, I have been heavily involved in this process.\r\n\r\nI like to initiate a larger discussion about how to teach programming to undergraduate students, especially because in the last decades programming got more and more important in science and due to e.g. the Bologna reform in Europe, it should be easier to change between universities after e.g. the Bachelor program.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/B_WoteRvK2I?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/B_WoteRvK2I?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/B_WoteRvK2I/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=B_WoteRvK2I", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:42.951", "updated": "2014-07-16T14:51:43.923"}, {"category": "SciPy 2014", "language": "English", "slug": "the-berkeley-institute-for-data-science-a-place-f", "speakers": ["Fernando P\u00e9rez"], "tags": [], "related_urls": [], "id": 2820, "state": 1, "title": "The Berkeley Institute for Data Science a place for people like us", "summary": "I will describe the new Berkeley Institute for Data Science (BIDS), part of a collaboration with UW and NYU funded by the Moore and Sloan Foundations. It will be a space for the open and interdisciplinary work that is typical of the SciPy community.  In the creation of BIDS, the role of open source scientific tools for Data Science, and specifically the SciPy ecosystem, played an important role.", "description": "In 2013, the Gordon and Betty Moore and the Alfred P. Sloan foundations [awarded](http://www.moore.org/programs/science/data-driven-discovery/data-science-environments) UC Berkeley, U. Washington and NYU for a collaborative, $38M in support of a 5-year initiative to create novel environments for Data Science.  This project was driven by the recognition that computing and data analysis have now become the backbone of all scientific research, and yet the teams, collaborations and individuals that make this possible typically encounter significant barriers in today's academic environments.\r\n\r\nThe SciPy community is one of the poster children of this issue: many of our members live \"officially\" in traditional, discipline-oriented scientific research, and yet we have committed time and effort to creating an open ecosystem of tools for research.  As we all know, this is often done with little support from the standard incentive structures of science, be it publication venues, funding agencies or hiring, tenure and promotion committees.\r\n\r\nThe launch of this initiative is an important moment, as it signals the recognition of this problem by important and well-respected foundations in science.  At UC Berkeley, we took this opportunity to create the new [Berkeley Institute for Data Science](http://vcresearch.berkeley.edu/datascience/bids-launch-dec-12). In this effort, the open source tools of the SciPy community will play a central role.\r\n\r\nIn this talk, I will describe the larger context in which this initiative has been created, as well as the scientific scope of our team, our goals, and the opportunities that we will try to provide with this space.  We expect that this new institute, together with our partners at UW and NYU, will play an important role in support of the great work of the SciPy ecosystem.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/q5yAy4WWTyU?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/q5yAy4WWTyU?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/q5yAy4WWTyU/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=q5yAy4WWTyU", "whiteboard": "", "recorded": "2014-07-10", "added": "2014-07-15T22:45:43.062", "updated": "2014-10-26T16:27:52.648"}]}