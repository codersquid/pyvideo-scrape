{"count": 3439, "next": "http://pyvideo.org/api/v2/video/?page=73&format=json", "previous": "http://pyvideo.org/api/v2/video/?page=71&format=json", "results": [{"category": "EuroPython 2014", "language": "English", "slug": "welcome-to-europython2104", "speakers": ["Fabio Pliger", "Mike M\u00fcller"], "tags": [], "related_urls": [], "id": 3049, "state": 1, "title": "Welcome to EuroPython 2014: Where the European Python Community Meets", "summary": "", "description": "Welcome starts at [4:26 minutes](https://www.youtube.com/watch?v=6ugj7G9MUkI#t=266)\r\n", "quality_notes": "", "copyright_text": "http://creativecommons.org/licenses/by/3.0/", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/6ugj7G9MUkI?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/6ugj7G9MUkI?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i.ytimg.com/vi/6ugj7G9MUkI/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=6ugj7G9MUkI", "whiteboard": "", "recorded": "2014-07-21", "added": "2014-07-31T00:46:36.272", "updated": "2014-08-02T13:28:35.283"}, {"category": "EuroPython 2014", "language": "English", "slug": "what-can-python-learn-from-haskell", "speakers": ["Bob Ippolito"], "tags": [], "related_urls": [], "id": 3046, "state": 1, "title": "What can python learn from Haskell?", "summary": "What can we learn from Erlang or Haskell for building reliable high\r\nconcurrency services?\r\n", "description": "What can we learn from Erlang or Haskell for building reliable high\r\nconcurrency services? Bob was involved in many Python projects but\r\nargues that for some domains there may be better methods found\r\nelsewhere. He started looking for alternatives back in 2006 when\r\nbuilding high concurrency services at Mochi Media (originally with\r\nTwisted), which led him to the land of Erlang and later Haskell. Bob is\r\ngoing to talk about what he learned along the way. In particular, he\u2019ll\r\ncover some techniques that are used in functional programming languages\r\nand how they can be used to solve problems in more performant, robust\r\nand/or concise ways than the standard practices in Python. He is also\r\ngoing to discuss some potential ways that the Python language and its\r\nlibrary ecosystem could evolve accordingly.", "quality_notes": "", "copyright_text": "http://creativecommons.org/licenses/by/3.0/", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/eVChXmNjV7o?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/eVChXmNjV7o?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i.ytimg.com/vi/eVChXmNjV7o/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=eVChXmNjV7o", "whiteboard": "", "recorded": "2014-07-21", "added": "2014-07-31T00:46:35.949", "updated": "2014-08-02T13:30:43.494"}, {"category": "SciPy 2014", "language": "English", "slug": "astropy-in-2014-whats-new-where-we-are-headed", "speakers": ["Perry Greenfield"], "tags": ["astropy"], "related_urls": [], "id": 2778, "state": 1, "title": "Astropy in 2014: What's new, where we are headed", "summary": "We report on the progress made on the Astropy Project in the past year highlighting the new capabilities added as well as the near-term development plans.", "description": "Astropy continues to see significant growth in available software, developers, and users. A new major release (V0.3) was made in the past year as well as many minor releases. V0.4 is scheduled for release by the time of conference and will include support for the VO SAMP protocol. We will report on the progress made in building and enhancing the core libraries in the Astropy Project, including a new model and fitting framework, enhanced units, quantities, and table functionality, a VO cone search tool, and a new convolution subpackage. We'll review the current set of tools available, highlighting in particular the new capabilities present. We will also give an overview of current activities and development plans for the core and affiliated packages, as well as adding new resources/tutorials for learning how to use astropy.", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/R12BY23xczI?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/R12BY23xczI?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/R12BY23xczI/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=R12BY23xczI", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:37.958", "updated": "2014-07-15T22:54:46.425"}, {"category": "SciPy 2014", "language": "English", "slug": "cartopy", "speakers": ["Richard Hattersley"], "tags": [], "related_urls": [], "id": 2782, "state": 1, "title": "Cartopy", "summary": "Cartopy is a Python package which builds on Proj.4 to define coordinate reference systems for the transformation and visualisation of geospatial data. It has a simple matplotlib interface for publication quality visualisation. This talk will outline some of cartopy's functionality and demonstrate some practical applications within the realm of scientific presentation of geospatial data.", "description": "The practice of representing geospatial data upon a flat surface is known as\r\ncartography, and the topological implications of projecting fundamentally 3D\r\ndata onto a 2 dimensional surface has been the challenge of map-makers since\r\ntime immemorial. Geospatial visualisation software is often implemented without\r\nconsideration for the 3rd dimension and this commonly results in problems\r\naround the dateline or at the poles. For small areas these problems are often\r\nnot apparent and mostly surmountable, but at a global scale, such as when\r\nvisualising output from GCMs (General circulation models), the underlying\r\nrepresentation must be addressed head-on in order to visualise the data\r\n\"impact free\".\r\n\r\nCartopy is a Python package which builds on top of\r\nProj.4 to define coordinate reference systems for the transformation and\r\nvisualisation of geospatial data. As well as the fundamental transformations\r\nthere is also a matplotlib interface allowing easy generation of maps with the\r\nsame publication quiality expected of matplotlib. Cartopy employs several\r\ntechniques to handle geospatial data correctly, including true spherical\r\ninterpolation for raster data, and Shapely geometry interpolate-and-cut\r\ntransformations for geospatial vector data.\r\n\r\nThis talk will outline some\r\nof the capabilities of cartopy, and continue onto its practical application\r\nwithin the realm of scientific presentation of geospatial data.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/Ax75kA4_kRo?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/Ax75kA4_kRo?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/Ax75kA4_kRo/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=Ax75kA4_kRo", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:38.721", "updated": "2014-07-15T22:56:35.894"}, {"category": "SciPy 2014", "language": "English", "slug": "deploying-python-tools-to-gis-users", "speakers": ["Shaun Walbridge"], "tags": ["gis"], "related_urls": [], "id": 2775, "state": 1, "title": "Deploying Python Tools to GIS Users", "summary": "The geospatial community has coalesced around Python, both in the commercial and open source spaces. In this talk, I'll show how Python tools can be shared with users of ArcGIS, a commercial GIS system which uses Python as its primary development environment. By constructing small Python wrappers, code can be shared in graphical tools which enable non-programmers to use what you've built.", "description": "Geospatial data is frequently manipulated directly using Python tools, commonly\r\nbuilt on top of powerful libraries such as GDAL, GEOS and NetCDF. Delivering\r\nmodel results to end users in many instances requires providing tools in\r\nfamiliar graphical environments, such as desktop GIS systems, which can permit\r\nusers without programming knowledge to integrate models and results into their\r\nexisting scientific workflows. This talk discusses how to construct simple\r\nwrappers around existing Python programs to enable their use by ArcGIS, a\r\ncommonly used commercial GIS.\r\n\r\nTwo separate approaches will be\r\nillustrated: creating Python toolboxes, or collections of tools embeddable in\r\nworkflows, and creating customized Python graphical add-ins, which can control\r\nthe graphical environment provided within ArcGIS. Building contextual help,\r\ninteractive widgets, and leveraging `numpy` for direct data integration will be\r\ndiscussed. While ArcGIS exposes much of its functionality via the `ArcPy`\r\npackage, this talk instead focuses on integrating code from other environments,\r\nand doesn't presume existing ArcGIS expertise.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/_rMNUAtLnPw?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/_rMNUAtLnPw?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/_rMNUAtLnPw/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=_rMNUAtLnPw", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:37.625", "updated": "2014-07-15T22:57:37.559"}, {"category": "SciPy 2014", "language": "English", "slug": "enhancements-to-ginga-an-astronomical-image-view", "speakers": ["Eric Jeschke"], "tags": ["astronomy"], "related_urls": [], "id": 2777, "state": 1, "title": "Enhancements to Ginga: an Astronomical Image Viewer and Toolkit", "summary": "We describe recent developments in the Ginga package, a open-source astronomical image viewer and toolkit written in python and hosted on Github.  The package was introduced to the scientific python community at SciPy 2013 and has received a number of enhancements since then based on user feedback.  The talk includes an image mosaicing demo of a wide-field camera exposure with 116 4Kx2K CCDs.", "description": "Ginga is an open-source astronomical image viewer and toolkit written in python and [hosted on Github](https://github.com/ejeschke/ginga).  It uses and inter-operates with several key scientific python packages: numpy, scipy, astropy and matplotlib.\r\n\r\nIn this talk/poster we describe and illustrate recent enhancements to the package since the introductory talk at SciPy 2013, including:\r\n\r\n\r\n* modular/pluggable interfaces for world coordinate systems, image file I/O and star and image catalogs\r\n* support for rendering into matplotlib figures\r\n* support for image mosaicing\r\n* support for image overlays\r\n* customizable user-interface bindings\r\n* improved documentation\r\n* self contained Mac OS X packages\r\n\r\nDuring the talk we will demonstrate the mosaicing plugin that is being used with several instruments at Subaru Telescope in Hawaii, including the new Hyper Suprime-Cam wide-field camera with 116 separate 4Kx2K CCDs.\r\n\r\nThe talk/poster may be of interest to anyone developing code in python needing to display scientific image (CCD or CMOS) data and astronomers interested in python-based quick look and analysis tools.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/wa_0SuVckGQ?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/wa_0SuVckGQ?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/wa_0SuVckGQ/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=wa_0SuVckGQ", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:37.832", "updated": "2014-07-15T22:59:53.756"}, {"category": "SciPy 2014", "language": "English", "slug": "epipy-visualization-of-emerging-zoonoses-through", "speakers": ["Caitlin Rivers"], "tags": ["epipy", "vis"], "related_urls": [], "id": 2767, "state": 1, "title": "Epipy: Visualization of Emerging Zoonoses Through Temporal Networks", "summary": "We introduce two new plots for visualizing infectious disease outbreaks. Case tree plots depict the emergence and growth of clusters of zoonotic disease over time. Checkerboard plots also represent temporal case clusters, but do not construct transmission trees. These plots visualize outbreak dynamics  and allow for analyses like case fatality risk stratified by generation.", "description": "We present two new visualizations, [case tree plots](https://github.com/cmrivers/epipy/blob/master/figs/example_casetree.png)\r\nand [checkerboard](https://github.com/cmrivers/epipy/blob/master/figs/test_checkerboard.png)\r\nplots, for visualizing emerging zoonoses.\r\n\r\nZoonoses represent an estimated 58% of all human infectious diseases, and 73%\r\nof emerging infectious diseases. Recent examples of zoonotic outbreaks include\r\nH1N1, SARS and Middle East Respiratory Syndrome, which have caused thousands of\r\ndeaths combined. The current toolkit for visualizing data from these emerging\r\ndiseases is limited.\r\n\r\nCase tree and checkerboard plots were developed to address that gap.\r\nThe visualizations are best suited for diseases like SARS for which there are a\r\nlimited number of cases, with data available on human to human transmission.\r\nThey a) allow for easy estimation of epidemiological parameters like basic\r\nreproduction number b) indicate the frequency of introductory events, e.g.\r\nspillovers in the case of zoonoses c) represent patterns of case attributes\r\nlike patient sex both by generation and over time.\r\n\r\nCase tree plots depict the emergence and growth of clusters of disease over\r\ntime. Each case is represented by a colored node. Nodes that share an\r\nepidemiological link are connected by an edge. The color of the node varies\r\nbased on the node attribute; it could represent patient sex, health status\r\n(e.g. alive, dead), or any other categorical attribute. Node placement along\r\nthe x-axis corresponds with the date of illness onset for the case.\r\n\r\nA second visualization, the checkerboard plot, was developed to complement case\r\ntree plots. They can be used in conjunction with case tree plots, or in\r\nsituations where representing a hypothetical network structure is\r\ninappropriate.\r\n\r\nThe plots are available in the open source package epipy, which is available on\r\n[github](https://github.com/cmrivers/epipy). Detailed documentation and\r\nexamples are also [available](cmrivers.github.io/epipy). In addition to these\r\nvisualizations, epipy includes functions for common epidemiology calculations\r\nlike odds ratio and relative risk.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/JDtIDCVrxgk?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/JDtIDCVrxgk?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/JDtIDCVrxgk/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=JDtIDCVrxgk", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:36.773", "updated": "2014-07-15T23:01:32.155"}, {"category": "SciPy 2014", "language": "English", "slug": "holopy-holograpy-and-light-scattering-in-python", "speakers": ["Tom Dimiduk"], "tags": ["holopy"], "related_urls": [], "id": 2765, "state": 1, "title": "HoloPy: Holograpy and Light Scattering in Python", "summary": "Digital holography microscopy is a powerful tool for fast 3D imaging of soft matter systems. However, making measurements from holograms requires special computation. HoloPy is a set of tools for reconstructing and fitting to holograms. It also includes tools for computing light scattering, setting up inverse problems, and working with images and metadata.", "description": "Digital holographic microscopy is fast and powerful tool for 3D imaging.\r\nHolography captures information about a 3D scene onto a 2D camera using\r\ninterference. This means that the speed of holographic imaging is limited only\r\nby camera speed, making holography an ideal tool for studying fast processes in\r\nsoft matter systems. However, making use of this encoded information requires\r\nsignificant computational post processing. We have developed and released\r\n[HoloPy](http://manoharan.seas.harvard.edu/holopy/), a python based tool for\r\ndoing these calculations. \r\n\r\nThe traditional method for extracting\r\ninformation from holograms is to optically reconstruct by shining light through\r\na hologram to obtain an image of the recorded scene. HoloPy implements the\r\ndigital equivalent of this, numerical reconstruction, in the form of light\r\npropagation by convolution. This is a fast technique based on fast Fourier\r\ntransforms, which effectively allows refocusing a holographic image after it is\r\ntaken. \r\n\r\nFor systems where a detailed scattering model is available, Lee\r\nand coworkers showed that it is possible to make more precise measurements by\r\nfitting a scattering model to a recorded hologram\r\n[[1](http://physics.nyu.edu/grierlab/index12c/)]. We have extended this\r\ntechnique to clusters of spheres\r\n[[2](http://arxiv.org/pdf/1202.1600)][[3](http://people.seas.harvard.edu/~vnm/pdf/Perry-Faraday_Discussions-2012.pdf)]\r\nand to non-spherical particles [[4](http://arxiv.org/pdf/1310.4517)]. HoloPy\r\nimplements all of these fitting techniques such that they can be used with a\r\nfew lines of python code. HoloPy also exposes an interface to all of its\r\nscattering models compute light scattering of microscopic particles or clusters\r\nof particles for other purposes. \r\n\r\nHoloPy is open source (GPLv3) and is\r\nhosted on [launchpad](https://launchpad.net/holopy). HoloPy uses Numpy for most\r\nof its manipulations, though it calls out to Fortran and\r\n[C](http://code.google.com/p/a-dda) codes to compute light scattering. HoloPy\r\nalso includes matplotlib and mayavi based tools for visualizing holograms and\r\nparticles. \r\n\r\n[1] Lee et.al., Optics Express, Vol. 15, Issue 26, pp.\r\n18275-18282 (2007)\r\n\r\n[2] Fung et. al., JQSRT, Vol 113, Issue 18, pp.\r\n2482-2489 (2012)\r\n\r\n[3] Perry et. al., Faraday Discussions, Vol 159, pp.\r\n211-234 (2012)\r\n\r\n[4] Wang et. al. JQSRT, (2014)\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/uW6bMEcFX4A?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/uW6bMEcFX4A?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/uW6bMEcFX4A/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=uW6bMEcFX4A", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:36.551", "updated": "2014-07-15T23:03:16.597"}, {"category": "SciPy 2014", "language": "English", "slug": "how-interactive-visualization-led-to-insights-in", "speakers": ["Rebecca Perry"], "tags": ["holopy"], "related_urls": [], "id": 2766, "state": 1, "title": "How Interactive Visualization Led to Insights in Digital Holographic Microscopy", "summary": "Digital holographic microscopy is a fast 3D imaging technique.  A camera records a time series of light scattering patterns as standard 2D images and then post-processing routines extract 3D information.  By creating a GPU-accelerated GUI on top of the Holopy package, we noticed unexpected discrepancies between the different models used during post-processing.", "description": "Digital holographic microscopy is a fast 3D imaging technique ideally suited to\r\nstudies of micron-sized objects that diffuse through random walks via Brownian\r\nmotion [[1]](http://dx.doi.org/10.1364/OE.15.018275).  Microspheres fit this\r\ncategory and are widely used in biological assays and as ideal test subjects\r\nfor experiments in statistical mechanics.  Microspheres suspended in water move\r\ntoo quickly to monitor with confocal microscopy.  With digital holographic\r\nmicroscopy, 2D images encoding 3D volumes can be recorded at thousands of\r\nframes per second\r\n[[2]](http://www.nature.com/nmat/journal/v11/n2/abs/nmat3190.html).  The\r\ncomputationally challenging part of digital holographic microscopy is\r\nextracting the 3D information during post-processing.\r\n\r\nThe open source\r\n[Holopy](https://launchpad.net/holopy) package which relies heavily on SciPy\r\nand NumPy is used to recover the 3D information via one of two techniques:\r\nreconstruction by numerical back-propagation of electromagnetic fields or\r\nmodeling forward light scattering with Mie theory.  The parameter space\r\ndescribing the imaged volume is multidimensional.  Even for simple micron-sized\r\nspheres, a hologram depends on each sphere's radius and index of refraction in\r\naddition to its 3D position.  By supplementing Holopy with a [GPU-accelerated\r\nGUI](https://github.com/RebeccaWPerry/holography-gpu) using PyQt4, we enabled\r\nusers to interactively adjust the system parameters and see a modeled digital\r\nhologram change in response.\r\n\r\nSimply adding the capability of\r\ninteractively manipulating holograms in a GUI led us to notice unexpected\r\ndiscrepancies between the two modeling techniques and failures of both,\r\nsuggesting further experiments.  We observed that the numerical light\r\npropagation technique only accurately characterizes the light within a cone\r\nstretching from the extent of the image back towards the object.  Neither model\r\naccurately characterizes the light upstream of the object toward the light\r\nsource.  The GUI was a natural format to interact with the theory and gain\r\ninsight because it showed us the models in an analogous format to how we see\r\nthe data on the microscope.  Other scientific projects may benefit from tools\r\nthat allow experimentalists to interact with theory in the same way they\r\ninteract with their experiments.\r\n\r\n[1] Lee et.al., Optics Express, Vol.\r\n15, Issue 26, pp. 18275-18282 (2007) doi: 10.1364/OE.15.018275.\r\n\r\n[2] Kaz\r\net.al., Nature Materials, Vol. 11, pp. 138\\u2013142 (2012)\r\ndoi:10.1038/nmat3190.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/-IjIpX8QsAM?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/-IjIpX8QsAM?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/-IjIpX8QsAM/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=-IjIpX8QsAM", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:36.661", "updated": "2014-07-15T23:04:43.689"}, {"category": "SciPy 2014", "language": "English", "slug": "how-to-choose-a-good-colour-map", "speakers": ["Damon McDougall"], "tags": ["vis"], "related_urls": [], "id": 2768, "state": 1, "title": "How to Choose a Good Colour Map", "summary": "Representing data through colours is a very common approach to conveying important information to an audience. We suggest some best practices scientists should consider when deciding how they should present their results.", "description": "Representing data through colours is a very common approach to conveying important information to an audience.  This is done throughout all fields in the scientific community and stakes a claim in the commercial and marketing realm as well.  Colour maps and contour maps are the preferred way for scientists to visualise three-dimensional data in two dimensions.  Research has shown that the choice of colourmap is crucial since the human brain interpolates hue poorly.  We suggest some best practices scientists should consider when deciding how they should present their results.  Specifically, we look at some examples of colourmaps that can easily be misinterpreted, making reference to an in-depth supportive study, and suggest alternative approaches to improve them.  We conclude by listing some open source tools that aid making good colourmap choices.  Kristen Thyng's talk on perception of colourmaps in matplotlib is an excellent follow-on from this.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/Alnc9E1RnD8?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/Alnc9E1RnD8?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/Alnc9E1RnD8/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=Alnc9E1RnD8", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:36.875", "updated": "2014-07-15T23:06:13.149"}, {"category": "SciPy 2014", "language": "English", "slug": "light-weight-real-time-event-detection-with-pytho", "speakers": ["Carson Farmer"], "tags": [], "related_urls": [], "id": 2781, "state": 1, "title": "Light-weight real-time event detection with Python", "summary": "Real-time feeds of user activity from various apps such as Twitter, Foursquare, and others are becoming increasingly available. These 'digital footprints' provide new means to understand how individuals utilize the places and spaces of urban environments. We present a light-weight framework for real-time event detection in a city based on existing SciPy libraries and real-time Twitter streams.", "description": "In this paper, we utilize real-time 'social information sources' to automatically detect important events at the urban scale. The goal is to provide city planners and others with information on *what* is going on, and *when* and *where* it is happening. Traditionally, this type of analysis would require a large investment in heavy-duty computing infrastructure, however, we suggest that a focus on real-time analytics in a lightweight streaming framework is the most logical step forward.\r\n\r\nUsing online Latent Semantic Analysis (LSA) from the [`gensim`][gensim] Python package, we extract 'topics' from tweets in an online training fashion. To maintain real-time relevance, the topic model is continually updated, and depending on parameterization, can 'forget' past topics. Based on a set of learned topics, a grid of spatially located tweets for each identified topic is generated using standard `numpy` and `scipy.spatial` functionality. Using an efficient streaming algorithm for approximating 2D kernel density estimation (KDE), locations with the highest density of tweets on a particular topic are located. Locations are semantically labeled using the learned topics, based on the assumption that events can be directly tied to a particularly popular topic at a particular location.\r\n\r\nTo facilitate real time visualization of results, we utilize the [`pico`][pico] Python/Javascript library as a real-time bridge between server-side Python analysis and client-side Javascript visualization. This enables fast, responsive interactivity of computationally intensive tasks. Additionally, since `pico` allows streaming data from Python to Javascript, updates to the web-interface are sent and consumed as needed, such that only significant changes in an event's status, or the introduction of a new event, will cause updates to the visualizations. Finally, because all models, data structures, and outputs on the server side are pickle-able Python objects, this entire framework is small enough to be deployed on almost any server with Python installed.\r\n\r\n[pico]: https://github.com/fergalwalsh/pico\r\n[gensim]: https://github.com/piskvorky/gensim/\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/iT_QmeJsBhE?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/iT_QmeJsBhE?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/iT_QmeJsBhE/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=iT_QmeJsBhE", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:38.627", "updated": "2014-07-15T23:07:49.753"}, {"category": "SciPy 2014", "language": "English", "slug": "multi-purpose-particle-tracking", "speakers": ["Daniel B. Allan"], "tags": [], "related_urls": [], "id": 2764, "state": 1, "title": "Multi Purpose Particle Tracking", "summary": "In many scientific contexts it is necessary to identify and track features in video. Several labs with separate projects and priorities collaborated to develop a common, novice-accessible package of standard algorithms. The package manages optional high-performance components, such as numba, and interactive tools to tackle challenging data, while prioritizing testing and easy adoption by novices.", "description": "Tracking the motion of many particles is an established technique [[Crocker, J.C., Grier, D.G.](http://dx.doi.org/10.1006/jcis.1996.0217)], but many physicists, biologists, and chemical engineers still (make their undergraduates) do it by hand. [Trackpy](https://github.com/soft-matter/trackpy), is a flexible, high-performance implementation of these algorithms in Python using the scientific stack -- including pandas, numba, the IPython notebook, and mpld3 -- which scales well to track, filter, and analyze tens of thousands of feature trajectories.  It was developed collaboratively by research groups at U. Chicago, U.  Penn, Johns Hopkins, and others.\r\n\r\nResearchers with very different requirements for performance and precision collaborate on the same package. Some original \"magic\" manages high-performance components, including numba, using them if they are available and beneficial; however, the package is still fully functional without these features.   Accessibility to new programmers is a high priority.\r\n\r\nBiological data and video with significant background variation can confound standard feature identification algorithms, and manual curation is unavoidable. Here, the high-performance group operations in pandas and the cutting-edge notebook ecosystem, in particular the interactive IPython tools and mpld3, enable detailed examination and discrimination.\r\n\r\nThe infrastructure developed for this project can be applied to other work. Large video data sets can be processed frame by frame, out of core. Image sequences and video are managed through an abstract class that treats all formats alike through a handy, idiomatic interface in a companion project dubbed [PIMS](https://github.com/soft-matter/pims).\r\n\r\nA suite of over 150 unit tests with automated continuous integration testing has ensured stability and accuracy during the collaborative process. In our experience, this is an unusual but worthwhile level of testing for a niche codebase from an academic lab.\r\n\r\nIn general, we have lessons to share from developing shared tools for researchers with separate priorities and varied levels of programming skill and interest.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/MxK7Fe4xfXM?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/MxK7Fe4xfXM?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/MxK7Fe4xfXM/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=MxK7Fe4xfXM", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:36.442", "updated": "2014-07-15T23:09:18.903"}, {"category": "SciPy 2014", "language": "English", "slug": "perceptions-of-matplotlib-colormaps", "speakers": ["Kristen M. Thyng"], "tags": ["vis"], "related_urls": [], "id": 2769, "state": 1, "title": "Perceptions of Matplotlib Colormaps", "summary": "On several issues related to the perception of colormaps...", "description": "The choice of colormap in a scientific figure significantly affects the way the presented information is perceived by the viewer. This follows on Damon McDougall's talk on how to choose a colormap for an application by delving deeper into several important issues and how well many of the available Matplotlib colormaps stand up against the concerns. For example, it is known that the human brain is better able to interpret changes in magnitude of the luminance and saturation of colors in colormaps instead of the hue. Also, some research has shown that logarithmic changes in brightness are perceived as linear changes. Next, being able to print a color plot in black and white from a published paper is sometimes mandatory and often desirable, and is related to the grey scale in a colormap. Finally, it is important to account for various types of color blindness when choosing a divergent colormap for the plot to be as accessible as possible. All of these concerns have implications for the design of colormaps, and will be examined in the context of the properties of the available Matplotlib colormaps in order to make a best choice for a given application.\r\n\r\nAbstract and slides available [on Github.](https://github.com/dmcdougall/scipy14-colormaps)\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/rkDgBvT-giw?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/rkDgBvT-giw?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/rkDgBvT-giw/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=rkDgBvT-giw", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:36.992", "updated": "2014-07-15T23:10:00.909"}, {"category": "SciPy 2014", "language": "English", "slug": "rasterio-geospatial-raster-data-access-for-progr", "speakers": ["Sean Gillies"], "tags": ["gis"], "related_urls": [], "id": 2771, "state": 1, "title": "Rasterio: Geospatial Raster Data Access for Programmers and Future Programmers", "summary": "Learn to read, manipulate, and write georeferenced imagery and other kinds of geospatial raster data using a productive and fun GDAL and Numpy-based library named Rasterio. It's a new open source project from the satellite team at Mapbox and is informed by a decade of experience using Python and GDAL.", "description": "Rasterio is a GDAL and Numpy-based Python library guided by lessons learned over a decade of using GDAL and Python to solve geospatial problems. Among these lessons: the importance of productivity, enjoyability, and serendipity.\r\n\r\nI will discuss the motivation for writing Rasterio and explain how and why it diverges from other GIS software and embraces Python types, protocols, and idioms.  I will also explain why Rasterio adheres to some GIS paradigms and bends or breaks others.\r\n\r\nFinally, I will show examples of using Rasterio to read, manipulate, and write georeferenced raster data. Some examples will be familiar to users of older Python GIS software and will illustrate how Rasterio lets you get more done with less code and fewer bugs. I will also demonstrate fun and useful features of Rasterio not found in other geospatial libraries.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/yI9_ozSIKlk?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/yI9_ozSIKlk?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/yI9_ozSIKlk/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=yI9_ozSIKlk", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:37.217", "updated": "2014-07-15T23:11:37.393"}, {"category": "SciPy 2014", "language": "English", "slug": "real-time-crunching-of-petabytes-of-geospatial-da", "speakers": ["Randy Sargent"], "tags": [], "related_urls": [], "id": 2772, "state": 1, "title": "Real time Crunching of Petabytes of Geospatial Data with Google Earth Engine", "summary": "Google Earth Engine is a platform designed to enable petabyte-scale scientific analysis and visualization of geospatial datasets.  Earth Engine provides a consolidated environment including a massive data catalog co-located with thousands of computers for analysis. This talk will discuss products that Earth Engine has produced, and how to access Earth Engine via its Python API.", "description": "Background\r\n==========\r\n\r\n* What is [Earth Engine](https://earthengine.google.org) at a high level?\r\n* Why did the Earth Engine (EE) project start? [To monitor global deforestation.](http://blog.google.org/2010/12/introducing-google-earth-engine.html)\r\n* What architecture design decisions were made, and why?\r\n    - Just-in-time computation model\r\n    - Lazy evaluation for real-time feedback\r\n\r\nThe Earth Engine Python API\r\n===========================\r\n\r\n* PyPI package: [earthengine-api](https://pypi.python.org/pypi/earthengine-api)\r\n* OAuth authentication\r\n* Using IPython Notebooks for algorithm development\r\n    - Special display methods for interactive maps\r\n\r\nPhilosophical goals and how they are manifested\r\n===============================================\r\n\r\n* Organize the world's (geospatial) information and make it universally accessible and useful\r\n* Facilitate open transparent science\r\n* Speed up science by reducing the effort required to test hypotheses\r\n* Enable collaborative algorithm development\r\n\r\nSelected Results\r\n================\r\n\r\n* Consumer-grade visualizations\r\n    - Time-lapse global scale interactive video - [blog post](http://googleblog.blogspot.com/2013/05/a-picture-of-earth-through-time.html), [interactive viewer (centered on Austin)](https://earthengine.google.org/#timelapse/v=30.27632,-97.74597,10.812,latLng&t=1.67)\r\n* Science-grade Data Products\r\n    - High-Resolution Global Maps of 21st-Century Forest Cover Change - [Science journal publication](http://www.sciencemag.org/content/342/6160/850), [blog post](http://googleresearch.blogspot.com/2013/11/the-first-detailed-maps-of-global.html), [interactive viewer](http://earthenginepartners.appspot.com/science-2013-global-forest)\r\n\r\nThe Future\r\n==========\r\n\r\n* Global-scale analysis challenges\r\n* An invitation for developers\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/8LZGBL4U3F4?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/8LZGBL4U3F4?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/8LZGBL4U3F4/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=8LZGBL4U3F4", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:37.322", "updated": "2014-07-15T23:12:43.769"}, {"category": "SciPy 2014", "language": "English", "slug": "simpletitk-advanced-image-analysis-for-python", "speakers": ["Bradley Lowekamp", "Luis Ibanez", "Matthew McCormick"], "tags": ["image analysis"], "related_urls": [], "id": 2763, "state": 1, "title": "SimpletITK: Advanced Image Analysis for Python", "summary": "SimpleITK brings advanced image analysis capabilities to Python. In particular, it provides support for 2D/3D and multi-components images with physical. SimpleITK exposes a large collection of image processing filters from ITK, including image segmentation and registration. SimpleITK is freely available as an open source package under the Apache 2.0 License.", "description": "SimpleITK provides scientific image analysis, processing, segmentation and registration for biomedical, microscopy and other scientific fields by supporting multi-dimensional images with physical locations [1]. It's is a layer build upon the Insight Segmentation and Registration Toolkit (ITK) [2].\r\n\r\nWhile there are many Python packages to process 2D photographic images, scientific image analysis adds additional requirements.  Images encountered in these domains often have anisotropic pixel spacing, or spatial orientations, and calculations are best performed in physical space as opposed to pixel space. \r\n\r\nSimpleITK brings to Python a plethora of capabilities for performing image analysis. Although SimpleITK was developed by the biomedical imaging community, it is also used for generic image processing. It differentiates from OpenCV in offering 3D images and multi-component images, and it differentiates from scipy by offering the abstraction of image classes and their associated data structures. This applies to images modalities such as CT scans, MRI, fMRI, ultrasound, and in microscopy modalities such as confocal, SEM, TEM, and traditional bright and dark field.\r\n\r\nAmong the key functionalities supported by SimpleITK are over 260 advanced image filtering and segmentation algorithms as well as access to scientific image file formats, including specialized formats such as DICOM, Nifti, NRRD, VTK and other formats that preserve 3D metadata. Example algorithms include Level Sets Segmentation including multi-phase, Label Maps, Region Growing, Statistical Classification, Advanced Thresholding, Geometrical Transformations, Deconvolution, Anti-Aliasing, Edge Detection, Mathematical Morphology on both labels and grayscale images and Fourier Analysis [4,5]. \r\n\r\nSimpleITK is an open source project with an active community, that builds upon the large amount of image analysis experience of the ITK community [3] working in biomedical images analysis since 1999, and that continues to grow year by year, aggregating state of the art algorithms .\r\n\r\nSimpleITK development is sponsored by the US National Library of Medicine.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/1cX3DQ5w6F0?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/1cX3DQ5w6F0?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/1cX3DQ5w6F0/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=1cX3DQ5w6F0", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:36.296", "updated": "2014-07-15T23:16:01.063"}, {"category": "SciPy 2014", "language": "English", "slug": "simulating-x-ray-observations-with-python", "speakers": ["John ZuHone"], "tags": [], "related_urls": [], "id": 2774, "state": 1, "title": "Simulating X-ray Observations with Python", "summary": "Constructing synthetic X-ray observations from hydrodynamical simulations and other data sources is made possible with a combination of the yt analysis toolkit with a number of other astronomical Python libraries.", "description": "X-ray astronomy is a rapidly expanding field, thanks to the many observations of existing observatories, such as _Chandra_ and _XMM-Newton_, and the anticipation of high-resolution spectral data from upcoming missions such as _Astro-H_ and _Athena+_. Understanding these observations and connecting them to astrophysical mechanisms requires not only detailed modeling of the underlying physics but reliable reproduction of the observed phenomena. I present a method of creating synthetic X-ray observations from numerical simulations, which leverages several astronomical Python libraries, including [yt](http://yt-project.org \\\"yt\\\"), [AstroPy](http://www.astropy.org \\\"AstroPy\\\"), and [PyXspec](https://heasarc.gsfc.nasa.gov/xanadu/xspec/python/html/ \\\"PyXspec\\\"). I will describe the method of generating the observations, the Python packages used, and applications of the method, including connecting observations of galaxy clusters with MHD simulations and preparing simulations for observation proposals.", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/fUMq6rmNshc?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/fUMq6rmNshc?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/fUMq6rmNshc/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=fUMq6rmNshc", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:37.534", "updated": "2014-07-15T23:16:31.704"}, {"category": "SciPy 2014", "language": "English", "slug": "software-for-panoptes-a-citizen-science-observat", "speakers": ["Josh Walawender", "Michael Butterfield"], "tags": [], "related_urls": [], "id": 2776, "state": 1, "title": "Software for Panoptes: A Citizen Science Observatory", "summary": "In this presentation, we describe the current status of software for Project Panoptes.  Our goal is to build low cost, reliable, robotic telescopes which can be used to detect transiting exoplanets.  Panoptes is designed from the ground up to be a citizen science project which will involve the public in all aspects of the science, from data acquisition to data reduction.", "description": "The goal of Project Panoptes (Panoptic Astronomical Networked OPtical observatory for Transiting Exoplanets Survey, see http://projectpanoptes.org/) is to build low cost, reliable, robotic telescopes which can be used to detect transiting exoplanets.  The hardware is designed to be standardized, using as many commercial off the shelf components as possible so that a Panoptes \"unit\" can be reproduced quickly and easily by students or amateurs.  In this way, many units can be deployed at many different sites to provide continuous and redundant sky coverage.  Panoptes is designed from the ground up to be a citizen science project which will involve the public in all aspects of the science, from data acquisition to data reduction.\r\n\r\nIn this presentation, we describe the current status of the Panoptes Observatory Control System (POCS, see https://github.com/panoptes/POCS), an open source, collaborative, python-based software package.  POCS is designed to be a simple as possible in order to make it accessible to non-experts.  As such, POCS is a state machine which transitions between a few well defined operating states.  We make extensive use of existing modules (notably astropy and pyephem).  The challenge we face in writing POCS to to balance our desire for simplicity and accessibility against capability.\r\n\r\nWe will also briefly describe the other software challenges of our project, specifically an algorithm designed to extract accurate photometry from DSLR images (color images obtained using a Bayer color filter array) rather than from the more traditional filtered monochrome CCD image.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/VDWXJQggFH8?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/VDWXJQggFH8?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/VDWXJQggFH8/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=VDWXJQggFH8", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:37.739", "updated": "2014-07-15T23:17:30.674"}, {"category": "SciPy 2014", "language": "English", "slug": "the-history-and-design-behind-the-python-geophysi", "speakers": ["Patrick Cole"], "tags": [], "related_urls": [], "id": 2780, "state": 1, "title": "The History and Design Behind the Python Geophysical Modelling and Interpretation (PyGMI) Package", "summary": "The development of geophysical software by individual scientists is achievable through languages such as Python. All goals behind developing a geophysical potential field interpretation and modelling software have been achieved to date. The implication of this is that innovation can be a driving force in projects, rather than waiting for commercial vendors to provide appropriate scientific tools.", "description": "The Council for Geoscience (CGS) is the so called \"Geological Survey\"\r\nof South Africa. Like many similar institutions around the world, financial\r\nrestrictions play a significant role in limiting what tools are available to\r\nscientists. It was from this need to stay scientifically current, while keeping\r\nthe software inexpensive, that the examination of Python first started and\r\nultimately ended up in the PyGMI project.\r\n\r\nThe origins of PyGMI started with two separate projects. The first was a joint\r\nproject where the CGS was responsible for the creation of a software interface\r\nfor cluster analysis code, developed by the University of Potsdam (Paasche et\r\nal 2009). The resulting project was done entirely in Python. Data could be\r\nimported, filtered, analyzed and displayed in graph form using Matplotlib.\r\n\r\nThe second project stemmed from the need to perform 3D modelling on geophysical\r\ndata. The creation of 3D models can be extremely time-consuming. Packages\r\navailable tend to follow either the modelling of individual 2.5D profiles,\r\nwhich are then joined up into 3D sections, or modelling fully in\r\nthree dimensions using polygonal based models. The initial idea was to use the\r\nVTK library as the means to create, display and interrogate the model, while\r\nusing the Scipy and Numpy libraries to perform the actual potential field\r\ncalculations. It soon became apparent that editing the resulting mesh quickly\r\nbecame complex and time consuming. The ability to easily create and change a\r\nmodel is the very basis of forward modelling and for this reason a new approach\r\nwas adopted. The newer 3D modelling package was designed to allow the user to\r\nmodel simply by drawing the model, in the same way one would draw views of a\r\nhouse using a paint program. This implies the need to have a front view, as\r\nwell as a top view. The model is therefore voxel based rather than polygonal.\r\nThe final model can be displayed either within the PyGMI software, or exported\r\nto Google Earth for examination.\r\n\r\nUltimately these two projects formed the basis of what is now the actual PyGMI\r\npackage -- which is a modular collection of various techniques, including\r\nmultivariate statistical analysis and potential field modelling. The interface\r\nfollows a flow diagram approach and the individual modules are independent\r\nenough to ensure that they do not interfere with code which has preceded them\r\nin previous modules.\r\n\r\nThe PyGMI software is available for free download at: [https://code.google.com/p/pygmi/](https://code.google.com/p/pygmi/)\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/5kM3tKkjoSw?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/5kM3tKkjoSw?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/5kM3tKkjoSw/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=5kM3tKkjoSw", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:38.524", "updated": "2014-07-15T23:22:17.583"}, {"category": "SciPy 2014", "language": "English", "slug": "the-kbase-narrative-bioinformatics-for-the-99", "speakers": ["Bill Rihl"], "tags": ["bioinformatics"], "related_urls": [], "id": 2762, "state": 1, "title": "The KBase Narrative Bioinformatics for the 99%", "summary": "The KBase Narrative builds on the IPython Notebook to provide a multi-user, virtualized Bioinformatics Laboratory Notebook that brings Experimental/Wetlab Biologists, students and the bio-curious into the world of Computational Biology. Tools for genome annotation, visualization, metabolic modeling and more are made available in a collaborative and educational web interface.", "description": "Computional Biology and Experimental Biology are two specialities that would deeply\r\nbenefit from more interaction - computationalists need access to data, biologists in\r\nwetlabs need computational tools. The KBase Narrative is a computerized laboratory\r\nnotebook that puts the power of the KBase predictive biology platform into the hands of\r\nexperimentalists and students. KBase provides cluster computation, analysis and modeling pipelines,\r\nlarge public datasets and a \"pluggable\" architecture for future services. The Narrative\r\nis an interface enabling the sharing of data, approaches and workflows on KBase. It\r\nalso serves as a teaching tool and publishing platform, allowing other scientists and\r\nstudents to observe and reproduce the processes that led to the published result.\r\n\r\nThe KBase Narrative is based on the IPython Notebook, extended in the following ways:\r\n\r\n* Notebooks are stored in a remote object store that enables versioning, provenance and sharing\r\n* Support for multiple users has been added, based on OAuth authentication against a \"cloud\" authentication service (Globus Online)\r\n* A framework for dynamically building form inputs for services using Python introspection and the IPython Traitlets package (a version of Traits) and displaying the output in JS visualization widgets\r\n* A Docker based provisioning system that builds and tears down sandboxed IPython Notebook servers on demand, providing a scalable, reasonable safe and easy to use environment for running hosted IPython notebooks with much smaller overhead than VM's\r\n* A heavily modified user interface that has been designed to support computational biology workflows\r\n\r\nThe current KBase Narrative was developed over the span of roughly 6 months by a small\r\nteam of developers and user interface experts - the short time scale was possible due to the\r\nhuge amount of functionality already provided by the IPython Notebook, and taking advantage\r\nof the productivity and power of the Python language.\r\n", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/52uP6NZa8rE?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/52uP6NZa8rE?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/52uP6NZa8rE/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=52uP6NZa8rE", "whiteboard": "", "recorded": "2014-07-14", "added": "2014-07-15T22:45:36.072", "updated": "2014-07-15T23:23:36.020"}]}