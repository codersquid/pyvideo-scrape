{"count": 3439, "next": "http://pyvideo.org/api/v2/video/?page=102&format=json", "previous": "http://pyvideo.org/api/v2/video/?page=100&format=json", "results": [{"category": "DjangoCon AU 2013", "language": "English", "slug": "keynote-the-myth-of-goldilocks-and-the-three-fra", "speakers": ["Dylan Jay"], "tags": [], "related_urls": [], "id": 2249, "state": 1, "title": "Keynote: The myth of goldilocks and the three frameworks, Pyramid, Django and Plone", "summary": "", "description": "", "quality_notes": "", "copyright_text": "CC-BY-SA", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/vW1ZhO-_ZQk?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/vW1ZhO-_ZQk?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/vW1ZhO-_ZQk/hqdefault.jpg", "duration": 50, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://s3.us.archive.org/ndvpyconau2013/Keynote_The_myth_of_goldilocks.mp4", "video_mp4_download_only": true, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=vW1ZhO-_ZQk", "whiteboard": "", "recorded": "2013-07-05", "added": "2013-07-13T01:07:24", "updated": "2014-04-08T20:28:26.311"}, {"category": "OpenStack Pycon AU 2013", "language": "English", "slug": "nova-v3-api", "speakers": ["Christopher Yeoh"], "tags": [], "related_urls": [], "id": 2253, "state": 1, "title": "Nova v3 API", "summary": "", "description": "", "quality_notes": "", "copyright_text": "CC-BY-SA", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/cXQ6abwqjg0?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/cXQ6abwqjg0?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/cXQ6abwqjg0/hqdefault.jpg", "duration": 60, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://s3.us.archive.org/ndvpyconau2013/Nova_v3_API_by_Christopher_Yeo.mp4", "video_mp4_download_only": true, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=cXQ6abwqjg0", "whiteboard": "", "recorded": "2013-07-05", "added": "2013-07-13T23:43:11", "updated": "2014-04-08T20:28:26.312"}, {"category": "DjangoCon AU 2013", "language": "English", "slug": "porting-django-apps-to-python-3-0", "speakers": ["Jacob Kaplan-Moss"], "tags": [], "related_urls": [], "id": 2242, "state": 1, "title": "Porting Django apps to Python 3", "summary": "Django 1.5 now supports Python 3, so now's the time to start thinking about porting your apps and sites. Come see how! I'll talk about the porting techniques that work, and present two case studies: porting a site, and porting a reusable app.", "description": "", "quality_notes": "", "copyright_text": "CC-BY-SA", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/xNZ4OVO2Z_E?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/xNZ4OVO2Z_E?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/xNZ4OVO2Z_E/hqdefault.jpg", "duration": 30, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://s3.us.archive.org/ndvpyconau2013/Porting_Django_apps_to_Python_.mp4", "video_mp4_download_only": true, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=xNZ4OVO2Z_E", "whiteboard": "", "recorded": "2013-07-05", "added": "2013-07-13T01:07:06", "updated": "2014-04-08T20:28:26.313"}, {"category": "DjangoCon AU 2013", "language": "English", "slug": "secrets-of-the-testing-masters", "speakers": ["Russell Keith-Magee"], "tags": [], "related_urls": [], "id": 2244, "state": 1, "title": "Secrets of the testing masters", "summary": "Django ship with a wide range of tools to help you test your web application, but some of the best tools for testing Django don't come in the box.\r\n\r\nIn this talk, you'll get a brief introduction to two of those tools - Mock and Factory Boy - showing when they should be used, and some practical examples of their usage in a Django test suite.\r\n", "description": "", "quality_notes": "", "copyright_text": "CC-BY-SA", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/a713rcagoYU?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/a713rcagoYU?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/a713rcagoYU/hqdefault.jpg", "duration": 30, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://s3.us.archive.org/ndvpyconau2013/Secrets_of_the_testing_masters.mp4", "video_mp4_download_only": true, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=a713rcagoYU", "whiteboard": "", "recorded": "2013-07-05", "added": "2013-07-13T01:07:11", "updated": "2014-04-08T20:28:26.315"}, {"category": "OpenStack Pycon AU 2013", "language": "English", "slug": "testtools-and-test-repository-the-python-test-f", "speakers": ["Robert Collins"], "tags": [], "related_urls": [], "id": 2254, "state": 1, "title": "Testtools and Test Repository - the Python test frameworks OpenStack uses", "summary": "", "description": "", "quality_notes": "", "copyright_text": "CC-BY-SA", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/Oe_HhBBbqbw?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/Oe_HhBBbqbw?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/Oe_HhBBbqbw/hqdefault.jpg", "duration": 30, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://s3.us.archive.org/ndvpyconau2013/Testtools_and_Test_Repository_.mp4", "video_mp4_download_only": true, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=Oe_HhBBbqbw", "whiteboard": "", "recorded": "2013-07-05", "added": "2013-07-13T23:43:19", "updated": "2014-04-08T20:28:26.316"}, {"category": "DjangoCon AU 2013", "language": "English", "slug": "the-server-side-the-coolest-parts-of-backend-dev", "speakers": ["Tom Eastman"], "tags": [], "related_urls": [], "id": 2246, "state": 1, "title": "The Server Side: The coolest parts of backend development with Django", "summary": "There are few feelings more sweet than being a web-app backend developer, and knowing that the vaguaries and frustrations of front-end design, Javascript inconsistencies, and web-browser quirks are \"Someone Else's Problem\". \r\n\r\nThe backend developer, instead, has just three goals: Make the system lightning fast and infinitely scalable; ensure its absolute security and impregnability; and guarantee its absolute correctness, stability, and general perfection in the face of all input at all times.\r\n\r\nI'll take that over having to debug CSS rendering quirks any day of the week.\r\n\r\nIn this talk I'll cover these three goals and how Django helps make each one achievable, including a tour of some of the lesser known features of the framework, such as:\r\n\r\n - Magic tricks you can do with Django's caching framework beyond the naive \"cache this page\", and its ability to take advantage of the browser's own cache in marvellous ways.\r\n - Taking Django's testing framework to its logical (and illogical) extremes. Including clever uses of selenium and webdriver to run unit tests, integration tests and even Javascript tests.\r\n - Considerations of Django use and web security. Including the sorts of things Django does a great job of protecting you from, and the things where your own due dilligence will always be required.", "description": "", "quality_notes": "", "copyright_text": "CC-BY-SA", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/nTMupredqR0?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/nTMupredqR0?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/nTMupredqR0/hqdefault.jpg", "duration": 45, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://s3.us.archive.org/ndvpyconau2013/The_Server_Side_The_coolest_pa.mp4", "video_mp4_download_only": true, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=nTMupredqR0", "whiteboard": "", "recorded": "2013-07-05", "added": "2013-07-13T01:07:16", "updated": "2014-04-08T20:28:26.317"}, {"category": "DjangoCon AU 2013", "language": "English", "slug": "unleash-the-ponies-using-feincms-to-add-content", "speakers": ["Greg Turner"], "tags": [], "related_urls": [], "id": 2243, "state": 1, "title": "Unleash the ponies! Using FeinCMS to add content tools that users love to any Django model", "summary": "Site editors often struggle with editing rich content and managing variations in layout in Django admin. By rich content we mean text, images, video, tables, and so on. Trying to squeeze all this content into a single rich-text editor is like trying to jam a magical pony into a dog kennel. A better approach is to use a rich content framework like FeinCMS. FeinCMS is a sensible, flexible framework which allows rich content of any shape to be manipulated within any Django model in your project.\r\n\r\nThis talk describes what FeinCMS does and how it works, and most importantly whether it should be pronounced to rhyme with \"Vein\" or \"Vine\". The talk is supported with working example code that shows the progression of a FeinCMS project through several levels of functionality, plus some real-world demonstrations of fully-developed functionality.\r\n\r\nA FeinCMS Document model is just like any Django model, except it has one or more 'templates'. Each 'template' has one or more regions, and each region is a place where an unlimited amount of rich content types can be added, removed or rearranged to form the content in that region. This is all wrapped up in a nifty lightweight Javascript interface for Django's admin, and a surprisingly simple implementation at the database level.\r\n\r\nThe types of content available in a given region is defined by a collection of abstract Django models (e.g. one model to represent a passage of text, another model to represent an image, and so on). Developers are free to define their own FeinCMS content types, using all the usual features of Django models.\r\n\r\nAt the HTML template level, each FeinCMS content item renders a standard template, and can optionally render different templates in different circumstances.\r\n\r\nThis flexibility allows Django developers to quickly design and build CMSes that match the content and layout perfectly, meaning happier content editors, fewer maintenance headaches and greater magical pony freedom.", "description": "", "quality_notes": "", "copyright_text": "CC-BY-SA", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/RnMsobX3soE?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/RnMsobX3soE?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/RnMsobX3soE/hqdefault.jpg", "duration": 45, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://s3.us.archive.org/ndvpyconau2013/Unleash_the_ponies_Using_FeinC.mp4", "video_mp4_download_only": true, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=RnMsobX3soE", "whiteboard": "", "recorded": "2013-07-05", "added": "2013-07-13T01:07:09", "updated": "2014-04-08T20:28:26.319"}, {"category": "OpenStack Pycon AU 2013", "language": "English", "slug": "wtf-is-openstack", "speakers": ["Tim Serong"], "tags": [], "related_urls": [], "id": 2256, "state": 1, "title": "WTF is OpenStack", "summary": "", "description": "", "quality_notes": "", "copyright_text": "CC-BY-SA", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/r7wNfw-MvLA?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/r7wNfw-MvLA?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/r7wNfw-MvLA/hqdefault.jpg", "duration": 30, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "http://s3.us.archive.org/ndvpyconau2013/WTF_is_OpenStack_by_Tim_Serong.mp4", "video_mp4_download_only": true, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=r7wNfw-MvLA", "whiteboard": "", "recorded": "2013-07-05", "added": "2013-07-13T23:47:31", "updated": "2014-04-08T20:28:26.320"}, {"category": "SciPy 2013", "language": "English", "slug": "accessing-the-virtual-observatory-from-python-sc", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 1962, "state": 1, "title": "Accessing the Virtual Observatory from Python; SciPy 2013 Presentation", "summary": "Authors: Plante, Raymond, NCSA/UofIL; Fitzpatrick, Mike, NOAO; Graham, Matthew, Caltech; Tody, Doug, NRAO\n\nTrack: Astronomy and Astrophysics\n\nOne of the goals of the Virtual Astronomical Observatory (VAO) project is to enable developers to integrate access to astronomical archives and services into applications through standardized interfaces. As part of this effort, we have developed two packages for accessing the Virtual Observatory through Python. The first tool, VAOpy, is a package built on AstroPy which provides enables discovery of data archive services through the VAO registry service as well as the searching of the archives for individual datasets such as images, spectra, and source catalogs. The purpose of this module is to provide the developer an easy to use interface that reflects knowledge of the standards upon which services are based. The second tool, VOClient, supports the same low-level API provided by VAOpy but adds additional higher-level capabilities and \"book-keeping\" that make it easier to develop sophisticated applications. This includes support for searching multiple archives, finding data for a list of sources, and collaborating with other desktop tools. Long running tasks are supported through asynchronous access to the underlying services and data caching. VOClient can send retrieved data records and datasets to other applications on the desktop through VO standard protocol known as SAMP.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/gm7p5ztkOZs?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/gm7p5ztkOZs?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/gm7p5ztkOZs/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=gm7p5ztkOZs", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:30", "updated": "2014-04-08T20:28:26.321"}, {"category": "SciPy 2013", "language": "English", "slug": "a-comprehensive-look-at-representing-physical-qua", "speakers": ["Trevor Bekolay"], "tags": ["scipy"], "related_urls": [], "id": 2012, "state": 1, "title": "A comprehensive look at representing physical quantities in Python", "summary": "Why tracking physical quantities is an essential function for any programming language heavily used in science and a possible unification of the existing packages that enable the majority of use cases.", "description": "Authors: Bekolay, Trevor, University of Waterloo\r\n\r\nTrack: General\r\n\r\nCode that properly tracks the units associated with physical quantities is self-documenting and far more robust to unit conversion errors. Unit conversion errors are common in any program that deal with physical quantities, and have been responsible for several expensive and dangerous software errors, like the Mars Climate Orbiter crash. Support for tracking units is lacking in commonly used packages like NumPy and SciPy. As a result, a whole host of packages have been created to fill this gap, with varying implementations. Some build on top of the commonly used scientific packages, adding to their data structures the ability to track units. Others packages track units separately, and store a mapping between units and the data structures containing magnitudes.\r\n\r\nI will discuss why tracking physical quantities is an essential function for any programming language heavily used in science. I will then compare and contrast all of the packages that currently exist for tracking quantities in terms of their functionality, syntax, underlying implementation, and performance. Finally, I will present a possible unification of the existing packages that enables the majority of use cases, and I will discuss where that unified implementation fits into the current scientific Python environment.", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/N-edLdxiM40?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/N-edLdxiM40?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/N-edLdxiM40/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=N-edLdxiM40", "whiteboard": "", "recorded": "2013-07-02", "added": "2013-07-04T10:08:38", "updated": "2014-04-08T20:28:26.323"}, {"category": "SciPy 2013", "language": "English", "slug": "advances-in-delivery-and-access-tools-for-coastal", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 1988, "state": 1, "title": "Advances in delivery and access tools for coastal ocean model data; SciPy 2013 Presentation", "summary": "Authors: Signell, Richard, US Geological Survey\n\nTrack: Meteorology, Climatology, Atmospheric and Oceanic Science\n\nCoastal ocean modelers are producers and consumers of vast and varied data, and spend significant effort on tasks that could be eliminated by better tools. In the last several years, standardization led by the US Integrated Ocean Observing System Program to use OPeNDAP for delivery of gridded data (e.g. model fields, remote sensing) and OGC Sensor Observation Services (SOS) for delivery of in situ data (e.g. time series sensors, profilers, ADCPs, drifters, gliders) has resulted in significant advancements, making it easier to deliver, find, access and analyze data. For distributing model results, the Unidata THREDDS Data Server and PyDAP deliver aggregated data via OPeNDAP and other web services with low impact on providers. For accessing data, NetCDF4-Python and PyDAP both allow efficient access to OPeNDAP data sources, but do not take advantage of common data models for structured and unstructured grids enabled by community-developed CF and UGRID conventions. This is starting to change with CF-data model based projects like the UK Met Office Iris project. Examples of accessing and visualizing both curvilinear and unstructured grid model output in Python will be presented, including both the IPython Notebook and ArcGIS 10.1.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/EA8v770EcxE?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/EA8v770EcxE?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/EA8v770EcxE/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=EA8v770EcxE", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:35", "updated": "2014-04-08T20:28:26.324"}, {"category": "SciPy 2013", "language": "English", "slug": "analyzing-ibm-watson-experiments-with-ipython-not", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 2004, "state": 1, "title": "Analyzing IBM Watson experiments with IPython Notebook; SciPy 2013 Presentation", "summary": "Authors: Bittner, Torsten, IBM\n\nTrack: General\n\nIBM's Emerging Technologies team was tasked with migrating the IBM Watson system that won the Jeopardy!-like game to a domain-independent codebase. This task started as a software engineering exercise and later became an information engineering exercise as we worked to optimize the system's question-answering ability for new domains. In this new paradigm the team would observe and measure a system behavior, such as its accuracy in generating candidate answers to a particular type of question, and then hypothesize what (software) change to the system would improve the behavior and how it would impact the original measurement. The team would then implement the change, re-run the system against a test dataset, analyze the gigabyte-sized test results to evaluate the difference in system behavior. By conducting many series of these experimental iterations, the team was able to significantly improve IBM Watson's question-answering performance.\n\nOur initial attempts at information engineering used Java and the D3 JavaScript library to extract, analyze and visualize metrics of the system's behavior. Wiki pages were used to document the many experiments and their configurations. However, this arrangement proved overly cumbersome for handling the large numbers of experiments we ran, and our need to share experimental details, visualizations and results with other teams. Furthermore, we also needed to enable a broader skill set of people -- beyond expert Java programmers -- to conduct analyses, create visualizations, and share findings.\n\nThis talk describes how we used the IPython notebook environment and the rich set of Python data science libraries (e.g. Pandas, NumPy/SciPy) to perform reproducible science, which resulted in improvements to IBM Watson's accuracy.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/tlontoyWX70?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/tlontoyWX70?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/tlontoyWX70/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=tlontoyWX70", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:37", "updated": "2014-04-08T20:28:26.325"}, {"category": "SciPy 2013", "language": "English", "slug": "an-open-source-system-for-de-identification-and-u", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 1972, "state": 1, "title": "An Open Source System for De-identification and Use of Medical Images; SciPy 2013 Presentation", "summary": "An Open Source System for De-identification and Use of Medical Images for Research\n\nAuthors: Miller, Jeffrey, Center for Biomedical Informatics, The Children's Hospital of Philadelphia\n\nTrack: Medical Imaging\n\nMedical images captured from X-ray, MRI, CT, and ultrasound modalities represent a wealth of data for clinical researchers. Direct access to imaging studies establishes a greater opportunity for research purposes than a text-only system. However, imaging data can be difficult to work with outside of clinical systems and can contain Protected Health Information (PHI) in diverse and unexpected locations, presenting a barrier for multi-institutional, collaborative research. While there are existing integration solutions, such as the Clinical Trials Processor, they do not provide for manual curation of images to screen for relevancy and PHI, a crucial step for using images within a research application. To address these issues, we developed a system for the end-to-end provisioning of de-identified image studies. This includes a Django app for users to review and record metadata for each study, a pipeline for anonymizing and provisioning images to a production image archive, and finally an application for viewing images in the browser as part of a research application. We take advantage of the Python Ruffus pipeline framework and the PyDICOM library to orchestrate the work of moving, anonymizing, and annotating millions of files in a repeatable and auditable manner. This workflow has been used to integrate images into AudGenDB (http://audgendb.chop.edu), a publicly available hearing impairment research database. The results of the AudGenDB image integration enables researchers to visualize and assess images in direct context with clinical and genetic variables for research subjects. The source code is available under a BSD license at http://github.com/cbmi/dicom-pipeline.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/BK6nfEAj40k?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/BK6nfEAj40k?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/BK6nfEAj40k/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=BK6nfEAj40k", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:32", "updated": "2014-04-08T20:28:26.327"}, {"category": "SciPy 2013", "language": "English", "slug": "a-portrait-of-one-scientist-as-a-graduate-student", "speakers": ["Paul Ivanov"], "tags": ["git", "reproducibility"], "related_urls": [{"url": "http://nbviewer.ipython.org/5122140/Portrait.ipynb", "description": "ipynb slides"}], "id": 1994, "state": 1, "title": "A Portrait of One Scientist as a Graduate Student", "summary": "a focus on specific tools and techniques invaluable in doing research in a reproducible manner.", "description": "Authors: Ivanov, Paul, UC Berkeley\r\n\r\nTrack: General\r\n\r\nIn this talk, I will focus on the how of reproducible research. I will focus on specific tools and techniques I have found invaluable in doing research in a reproducible manner. In particular, I will cover the following general topics (with specific examples in parentheses): version control and code provenance (git), code verification (test driven development, nosetests), data integrity (sha1, md5, git-annex), seed saving ( random seed retention ) distribution of datasets (mirroring, git-annex, metalinks), light-weight analysis capture ( ttyrec, ipython notebook)", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/Nj_8lwMKD_g?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/Nj_8lwMKD_g?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/Nj_8lwMKD_g/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": "", "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": "", "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": "", "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": "", "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=Nj_8lwMKD_g", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:36", "updated": "2014-04-08T20:28:26.328"}, {"category": "SciPy 2013", "language": "English", "slug": "a-rapidly-adaptable-imaging-measurement-platfor", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 1966, "state": 1, "title": "A Rapidly-Adaptable Imaging & Measurement Platform for Cancer Research; SciPy 2013 Presentation", "summary": "A Rapidly-Adaptable Analytical Imaging & Measurement Standardization Platform for Cancer Diagnostics Research\n\nAuthors: Garsha, Karl, Ventana Medical Systems Inc.; Ventura, Franklin, Ventana Medical Systems Inc.;\n\nTrack: Medical Imaging\n\nThe focus of personalized medicine is to develop rationally-designed therapeutics targeting specific molecular mechanisms of diseases such as cancer. For targeted therapeutics to be of value in complex disease states, such as cancer, patient-specific mechanism(s) of disease must be identified by physicians such that the appropriate targeted therapeutic(s) may be identified and administered. The ability to evaluate phenotype and genotype for multiplexed biomarkers at the cellular level, in the context of preserved tissue, provides important information for advancing the science of personalized medicine.\n\nClassical cancer diagnostic methods are based on direct inspection of prepared slides. In the classical approach, measurement and measurement standardization are limited by the constraints of human perception, established tradition and training. Our research seeks to empower physicians with new tools that diminish these existing limitations. Through Python, we bring together sophisticated nano-reporter technology, advanced microscopies, computational analysis and databasing technologies to establish feasibility of analytical tissue assay technology. Advancement of this technology is hoped eventually to enable powerful new opportunities for treatment of cancer.\n\nOur work is greatly accelerated through the collective efforts of the Python community. The ability to leverage and combine rich scientific Open Source projects including SciPy, VTK, ITK, PIL, wxPython, Matplotlib, \u00c2\u00b5Manager, and OMERO are central to enabling this ambitious effort. Python allows us the synergy of sophisticated high-level language interfaced with rich natively-compiled libraries. This capability allows us to maintain a remarkable level of plasticity necessary to adapt to fast-moving and diverse research problems, and scalability to visualize large and complex n-dimensional datasets. Rich GUI capabilities allow us to rapidly put powerful tools in the hands of medical researchers.\n\nChallenges include mechanisms to pass high-level data structures between native-compiled libraries, combining widgets from different GUI toolkits, memory limits, and the complexity of building self-contained installers/uninstallers for deployment to collaborator sites.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/DDIW2rKxrbI?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/DDIW2rKxrbI?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/DDIW2rKxrbI/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=DDIW2rKxrbI", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:32", "updated": "2014-04-08T20:28:26.330"}, {"category": "SciPy 2013", "language": "English", "slug": "automating-quantitative-confocal-microscopy-analy", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 1970, "state": 1, "title": "Automating Quantitative Confocal Microscopy Analysis; SciPy 2013 Presentation", "summary": "Authors: Fenner, Mark; Fenner, Barbara, King's College, Wilkes-Barre, PA\n\nTrack: Medical Imaging\n\nConfocal microscopy is a qualitative analytical tool used to visualize the associations between cellular processes and anatomical structures. Quantitative analysis of confocal images uses domain expertise, in the form of background correction, and statistical calculations to give semi-quantitative comparisons among experimental conditions. Extended automation of quantitative confocal methods will (1) reduce the time consuming effort of manual background correction and (2) give a fully quantitative method to associate cellular process with structure.\n\nThe purpose of this project is: (1) to develop automated methods to quantitatively assess colocalization of multiple fluorescent labels within confocal images and (2) to apply these methods to assess colocalization of trkB.t1 and BDNF to three types of organelles: endosomes, lysosomes, and transport organelles. Computing quantitative colocalization values requires image correction for background noise. We perform background correction in three ways: (1) manual, (2) automated heuristic analysis of the label intensity histograms, and (3) application of a regression model developed from a subset of manually corrected images. Using the corrected images, we compute a set of domain specific correlations: Pearson's and Mander's coefficients, the 'colocalization coefficients' (M1, M2, m1, and m2), and the 'overlap coefficients' (k1 and k2).\n\nThe project is implemented, end-to-end, in Python. Pure Python is used for managing file access, input parameters, and initial processing of the repository of 933 images. NumPy is used to apply manual background correction, compute the automated background corrections (reducing false positive results and manual labor), and to calculate the domain specific coefficients. We visualize the raw intensity values and computed coefficient values with Tufte-style panel plots created in matplotlib. A longer term goal of this work is to explore plausible extensions of dual-label coefficients to triple-label coefficients.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/ar5YtgiXfNI?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/ar5YtgiXfNI?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/ar5YtgiXfNI/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=ar5YtgiXfNI", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:32", "updated": "2014-04-08T20:28:26.331"}, {"category": "SciPy 2013", "language": "English", "slug": "breaking-the-diffraction-limit-with-python-and-sc", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 2016, "state": 1, "title": "Breaking the diffraction limit with python and scipy; SciPy 2013 Presentation", "summary": "Authors: Baddeley, David, Nanobiology Institute, Yale University\n\nTrack: General\n\nTextbook physics tells us that the resolution of a microsope is limited to half the wavelength of the radiation used. This means that structures smaller than ~250 nm cannot be resolved in an optical microscope, and that electron microscopy was required to study cellular nanostructures. Recent advances based on imaging stochastically switching fluorescent probes have allowed the diffraction limit to be circumvented and optical imaging to be performed with a resolution of 10-20 nm. These new methods, known as PALM (Photo-Activated Localisation Microscopy), STORM (STochastic Optical Reconstruction Microscopy), and a number of related acronyms are computationally intensive and involve detailed control of the microscope hardware.\n\nI will present a comprehensive package for PALM/STORM microscope control and image analysis written in python and scipy. The package is modular, and comes complete with a facility for distributed data analysis. In addition to the specialised localisation microscopy components, there are many aspects of the project which are likely to be interesting to the broader microscopy and image processing community. These include a generic microscope control package, an extensible 3D image viewer supporting many basic image processing tasks, a 3D deconvolution software (Richardson-Lucy and ICTM), as well as PSF simulation and pupil phase extraction code.\n\nMy knowledge of python has grown alongside the project, and In addition to giving an overview of the package, I will discuss some of the design choices and mistakes I've made along the way.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/KiVwsCBkFYk?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/KiVwsCBkFYk?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/KiVwsCBkFYk/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=KiVwsCBkFYk", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:39", "updated": "2014-04-08T20:28:26.332"}, {"category": "SciPy 2013", "language": "English", "slug": "bringing-astronomical-tools-down-to-earth-scipy", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 2022, "state": 1, "title": "Bringing astronomical tools down to earth; SciPy 2013 Presentation", "summary": "Authors: Droettboom, Michael, STScI; Dencheva, Nadia, STScI; Aldcroft, Tom, Harvard-Smithsonian Center for As\n\nTrack: General\n\nIn the process of developing the core tools in astropy, some modules have been developed that have wider applicability than just for astronomy. This talk will describe these tools and the approach taken by astropy towards these. These include general tools for handling units, and quantities with units, with capabilities not found in other unit packages, such as equivalency mappings. We have also developed a generic system for defining models and interfacing models with generic fitting algorithms in an easily extensible way. This system underlies our approach for mapping array coordinates to general world coordinate systems. Finally, a powerful table interface has been developed that handles many different data formats (currently focused mostly on astronomical varieties, but extensible to other fields as well).", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/AsOzSBgGU0I?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/AsOzSBgGU0I?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/AsOzSBgGU0I/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=AsOzSBgGU0I", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:39", "updated": "2014-04-08T20:28:26.334"}, {"category": "SciPy 2013", "language": "English", "slug": "climate-observations-from-acis-in-pandas-scipy-2", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 1982, "state": 1, "title": "Climate Observations from ACIS in pandas; SciPy 2013 Presentation", "summary": "Authors: Noon, William: Northeast Regional Climate Center\n\nTrack: Meteorology, Climatology, Atmospheric and Oceanic Science\n\nThe Applied Climate Information System (ACIS) has been developed by the Regional Climate Centers (RCCs) and has been providing relevant climate data and products for over a decade. Last year (2012) we release version 2 of our data access protocol and made the system open to general use. http://data.rcc-acis.org\n\nACIS aggregates weather observations reported at over 20,000 stations in North America over the last 100 years. These observations are collected from a number of sources and updated multiple times a day. At any point in time, the system will select the best available data and merge them into a coherent record. The daily/hourly observations are available as well as climate products summarized over various time intervals. http://www.rcc-acis.org\n\nThe ACIS Web Services use standard web requests and formats to defined the requested data product and return the results. This data can be further refined by the user in their prefered analysis environment.\n\nThis talk introduces a pandas data loader for the ACIS Web Services.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/HQe1qdINL-A?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/HQe1qdINL-A?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/HQe1qdINL-A/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=HQe1qdINL-A", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:34", "updated": "2014-04-08T20:28:26.335"}, {"category": "SciPy 2013", "language": "English", "slug": "data-agnosticism-feature-engineering-without-dom", "speakers": [], "tags": ["Tech"], "related_urls": [], "id": 2030, "state": 1, "title": "Data Agnosticism: Feature Engineering Without Domain Expertise; SciPy 2013 Presentation", "summary": "Authors: Kridler, Nicholas, Accretive Health\n\nTrack: General\n\nBits are bits. Whether you are searching for whales in audio clips or trying to predicit hospitalization rates based on insurance claims, the pro- cess is the same: clean the data, generate features, build a model, and iter- ate. Better features lead to a better model, but without domain expertise it is often difficult to extract those features. Numpy/Scipy, Matplotlib, Pandas, and Sci-kit Learn provide an excellent framework for data anal- ysis and feature discovery. This is evidenced by high performing models in the Heritage Health Prize and the Marinexplore Right Whale Detec- tion challenge. In both competitions, the largest performance gains came from identifying better features. This required being able to repeatedly visualize and characterize model successes and failures. Python provides this capability as well as the ability to rapidly implement and test new features. This talk will discuss how Python was used to develop competi- tive predictive models based on derived features discovered through data analysis.", "description": "", "quality_notes": "", "copyright_text": "http://www.youtube.com/t/terms", "embed": "<object width=\"640\" height=\"390\"><param name=\"movie\" value=\"http://youtube.com/v/bL4b1sGnILU?version=3&amp;hl=en_US\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://youtube.com/v/bL4b1sGnILU?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\" width=\"640\" height=\"390\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>", "thumbnail_url": "http://i1.ytimg.com/vi/bL4b1sGnILU/hqdefault.jpg", "duration": null, "video_ogv_length": null, "video_ogv_url": null, "video_ogv_download_only": false, "video_mp4_length": null, "video_mp4_url": null, "video_mp4_download_only": false, "video_webm_length": null, "video_webm_url": null, "video_webm_download_only": false, "video_flv_length": null, "video_flv_url": null, "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=bL4b1sGnILU", "whiteboard": "needs editing", "recorded": "2013-07-02", "added": "2013-07-04T10:08:40", "updated": "2014-04-08T20:28:26.336"}]}